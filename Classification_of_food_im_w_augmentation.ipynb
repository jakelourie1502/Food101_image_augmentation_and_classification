{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Image augmentation to improve performance on image classifier\n",
    "\n",
    "The dataset comprises 100 food categories, each with ~1000 images. I will initially run a ResNet style model and get a benchmark for classification.\n",
    "\n",
    "I will then use image augmentation, cropping and mirroring the images to increase the size of the training set to see if this increases performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/food/food_images_augmentation',\n",
       " '/home/ubuntu/.vscode-server/extensions/ms-toolsai.jupyter-2021.5.745244803/pythonFiles',\n",
       " '/home/ubuntu/.vscode-server/extensions/ms-toolsai.jupyter-2021.5.745244803/pythonFiles/lib/python',\n",
       " '/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/ubuntu/.local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/ubuntu/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import plotly\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models, Model, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, ZeroPadding2D, Flatten, Dense, Activation, Add\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import activations\n",
    "import os\n",
    "from PIL import ImageOps\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the images\n",
    "\n",
    "The images are a range of sizes, and we'll handle this by converting them all to 128x128, padding the outside where necessary\n",
    "\n",
    "Initially download using .tar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image into an 'image' object type\n",
    "def image_to_vector(file,size=128):\n",
    "    im_vec = Image.open(file)\n",
    "    #calculate height and width\n",
    "    width = im_vec.size[0]\n",
    "    height = im_vec.size[1]\n",
    "    #re-size to 1/4 of the size and convert to an array - we've already shown that this doesn't decrease performance\n",
    "    resize_factor = max(width,height) / 128\n",
    "    im_vec = np.array(im_vec.resize((int(width//resize_factor),int(height//resize_factor))))\n",
    "    \n",
    "    width = im_vec.shape[0]\n",
    "    height = im_vec.shape[1]\n",
    "    #Pad it out to a full 128 by 128\n",
    "    hor_pad_1 = int((size-im_vec.shape[0])/2)\n",
    "    hor_pad_2 = int((size-im_vec.shape[0]+1)/2)\n",
    "    ver_pad_1 = int((size - im_vec.shape[1])/2)\n",
    "    ver_pad_2 = int((size - im_vec.shape[1]+1)/2)\n",
    "    im_vec = np.pad(im_vec,pad_width=((hor_pad_1,hor_pad_2),(ver_pad_1,ver_pad_2),(0,0)))\n",
    "    return im_vec\n",
    "\n",
    "# /home/ubuntu/.keras/datasets/food-101/images/churros/1601.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will work with only the opening 3 food categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foie_gras\n",
      "club_sandwich\n",
      "cheese_plate\n"
     ]
    }
   ],
   "source": [
    "'''Load in images of food'''\n",
    "\n",
    "#go through all the images, put them into vector form, and then have a dictionary where each key is a type of image, and the value is a list of all those vectors.\n",
    "list_of_food = []\n",
    "unique_foods = {}\n",
    "x = np.zeros((3000,128,128,3)).astype(np.uint8)\n",
    "counter_cats, counter = 0,0\n",
    "folder = '/Users/jacoblourie/Downloads//Food_Images/Images'\n",
    "for food_cat in os.listdir(folder)[0:3]:\n",
    "    print(food_cat)\n",
    "    #there is a folder called .DS_store which we don't want\n",
    "    if (food_cat == '.DS_Store'):\n",
    "        continue\n",
    "    unique_foods[counter_cats]=food_cat\n",
    "\n",
    "    for file in os.listdir(f'{folder}/{food_cat}'):\n",
    "        file_ = f'{folder}/{food_cat}/{file}'\n",
    "        #here we are resizing\n",
    "        try:\n",
    "            im_vec = image_to_vector(file_)\n",
    "            x[counter] = im_vec.astype(np.uint8)\n",
    "            # plt.imshow(im_vec)\n",
    "            list_of_food.append(food_cat)\n",
    "            counter+=1\n",
    "        except:\n",
    "          print(f'{food_cat} had an error')\n",
    "    counter_cats+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Y labels and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y has 3000 numbers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club_sandwich</th>\n",
       "      <th>foie_gras</th>\n",
       "      <th>cheese_plate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   club_sandwich  foie_gras  cheese_plate\n",
       "0           1000       1000          1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get list of each value in a series with value counts\n",
    "df = pd.DataFrame(pd.Series(list_of_food).value_counts())\n",
    "#initialise blank array\n",
    "y=np.array([])\n",
    "for food_idx, food in unique_foods.items():\n",
    "    length =  df.loc[food]\n",
    "    y  = np.append(y, np.zeros(length)+food_idx)\n",
    "print(f'Y has {len(y)} numbers')\n",
    "display(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts_one_hot(x,y):\n",
    "    #ensure parallel sizes in case of image errors\n",
    "    x, y = x[:len(y)], y[:len(y)]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.067)\n",
    "\n",
    "    #normalise x values\n",
    "    x_train, x_test = x_train/255, x_test/255\n",
    "    one_hot = OneHotEncoder(sparse = False)\n",
    "\n",
    "    #create one hot values for y, and reshape to an array\n",
    "    one_hot_y_train= one_hot.fit_transform(y_train.reshape(-1,1))\n",
    "    one_hot_y_test= one_hot.fit_transform(y_test.reshape(-1,1))\n",
    "    return x_train, x_test, y_train, y_test, one_hot_y_train, one_hot_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, one_hot_y_train, one_hot_y_test = tts_one_hot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Case ResNet\n",
    "\n",
    "Initially, I will run a resnet model using this format for inspiration: https://neurohive.io/en/popular-networks/resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_20_3():\n",
    "    #By creating a subclass, we don't need to repeat the train_val_rpedict\n",
    "    \n",
    "    #Initialise with the input shape(ignoring examples) and output shape\n",
    "    def __init__(self, input_dims, output='softmax', classes='False',conv_k_reg=0.001,conv_b_reg=0.001,dense_k_reg=0.001,dense_b_reg=0.001,name='ResNet_512_512_3'): \n",
    "        \n",
    "        #Set regularisers\n",
    "        self.conv_k_reg = tf.keras.regularizers.L2(conv_k_reg)\n",
    "        self.conv_b_reg = tf.keras.regularizers.L2(conv_b_reg)\n",
    "        self.dense_k_reg = tf.keras.regularizers.L2(dense_k_reg)\n",
    "        self.dense_b_reg = tf.keras.regularizers.L2(dense_b_reg)\n",
    "\n",
    "        self.input_im = Input(shape=(input_dims))\n",
    "        \n",
    "        #start with a layer non resnet\n",
    "        x = Conv2D(64,kernel_size=(7,7),padding='valid',strides=(2,2), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(self.input_im)\n",
    "        x = Activation(activations.relu)(x)\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)\n",
    "        #2 non pool ones\n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x)\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)    \n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x,filters=(128,128))\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)   \n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x,filters=(256,256))\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)           \n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x,filters=(512,512))\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(1,1))(x)    \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(200,activation='relu',kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.dense_k_reg,bias_regularizer=self.dense_b_reg)(x)\n",
    "        x = Dense(200,activation='relu',kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.dense_k_reg,bias_regularizer=self.dense_b_reg)(x)\n",
    "        activation = output\n",
    "        if output == 'sigmoid':\n",
    "            classes = 1\n",
    "        x = Dense(classes, activation=activation,kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.dense_k_reg,bias_regularizer=self.dense_b_reg)(x)\n",
    "        self.model = Model(inputs = self.input_im, outputs= x,name=name)\n",
    "\n",
    "\n",
    "\n",
    "    def _resnet_layer(self,x, first_kernel=(3,3),second_kernel=(3,3), filters=(64,64)):\n",
    "        f1,f2=filters\n",
    "        #do one full layer convolution, with activation\n",
    "        x_skip = x\n",
    "        #do another 2 layers for the x that you're passing through the longer loops\n",
    "        x = Conv2D(f1, kernel_size=first_kernel,activation='relu',padding='same',strides=(1,1), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x)\n",
    "        x = Conv2D(f2, kernel_size=second_kernel,activation='relu',padding='same',strides=(1,1), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x)        \n",
    "        #conv the skip\n",
    "        x_ = Conv2D(f2, kernel_size=(1,1),padding='same',strides=(1,1), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x_skip)\n",
    "        \n",
    "        #add them back to together\n",
    "        x = Add()([x,x_])\n",
    "        #activation both of them\n",
    "        x = Activation(activations.relu)(x)        \n",
    "        return x\n",
    "    \n",
    "    def train_test_predict(self,x_train,y_train,x_test,y_test):\n",
    "        preds_train  = np.argmax(self.model.predict(x_train),axis=-1)\n",
    "        preds_test = np.argmax(self.model.predict(x_test),axis=-1)\n",
    "        self.current_train_prediction_score = {np.sum(y_train - preds_train == 0)/x_train.shape[0]}\n",
    "        self.current_test_prediction_score = {np.sum(y_test - preds_test == 0)/x_test.shape[0]}\n",
    "        print(f'train prediction percentage is {self.current_train_prediction_score}')\n",
    "        print(f'test prediction percentage is {self.current_test_prediction_score}')\n",
    "\n",
    "'''Other helper function'''\n",
    "#Plotting the accuracy of a second val set, and the historic performance of the validations et.\n",
    "def plot_accs(training_object):\n",
    "    val_acc, train_acc = training_object.history['val_acc'], training_object.history['acc']\n",
    "    x = np.linspace(1,len(val_acc),len(val_acc))\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x,val_acc) #= go.Scatter(x=x,y=val_acc,name='val_acc'), \n",
    "    plt.plot(x,train_acc) # ,name='train_acc')\n",
    "    plt.legend(('val_acc','train_acc'))\n",
    "    #     fig.add_trace(line_1)\n",
    "#     fig.add_trace(line_2)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_512_512_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 61, 61, 64)   9472        input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 61, 61, 64)   0           conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling2D) (None, 30, 30, 64)   0           activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 30, 30, 64)   36928       max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 30, 30, 64)   4160        max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_180 (Add)                   (None, 30, 30, 64)   0           conv2d_557[0][0]                 \n",
      "                                                                 conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 30, 30, 64)   0           add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 30, 30, 64)   36928       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 30, 30, 64)   4160        activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_181 (Add)                   (None, 30, 30, 64)   0           conv2d_560[0][0]                 \n",
      "                                                                 conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 30, 30, 64)   0           add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 30, 30, 64)   36928       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 30, 30, 64)   4160        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_182 (Add)                   (None, 30, 30, 64)   0           conv2d_563[0][0]                 \n",
      "                                                                 conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 30, 30, 64)   0           add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling2D) (None, 15, 15, 64)   0           activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 15, 15, 128)  73856       max_pooling2d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 15, 15, 128)  8320        max_pooling2d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_183 (Add)                   (None, 15, 15, 128)  0           conv2d_566[0][0]                 \n",
      "                                                                 conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 15, 15, 128)  0           add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 15, 15, 128)  147584      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 15, 15, 128)  16512       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_184 (Add)                   (None, 15, 15, 128)  0           conv2d_569[0][0]                 \n",
      "                                                                 conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 15, 15, 128)  0           add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 15, 15, 128)  147584      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 15, 15, 128)  16512       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_185 (Add)                   (None, 15, 15, 128)  0           conv2d_572[0][0]                 \n",
      "                                                                 conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 15, 15, 128)  0           add_185[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling2D) (None, 7, 7, 128)    0           activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 7, 7, 256)    295168      max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 7, 7, 256)    33024       max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_186 (Add)                   (None, 7, 7, 256)    0           conv2d_575[0][0]                 \n",
      "                                                                 conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 7, 7, 256)    0           add_186[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 7, 7, 256)    590080      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 7, 7, 256)    65792       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_187 (Add)                   (None, 7, 7, 256)    0           conv2d_578[0][0]                 \n",
      "                                                                 conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 7, 7, 256)    0           add_187[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 7, 7, 256)    590080      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 7, 7, 256)    65792       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_188 (Add)                   (None, 7, 7, 256)    0           conv2d_581[0][0]                 \n",
      "                                                                 conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 7, 7, 256)    0           add_188[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling2D) (None, 3, 3, 256)    0           activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 3, 3, 512)    1180160     max_pooling2d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 3, 3, 512)    131584      max_pooling2d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_189 (Add)                   (None, 3, 3, 512)    0           conv2d_584[0][0]                 \n",
      "                                                                 conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 3, 3, 512)    0           add_189[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 3, 3, 512)    2359808     activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 3, 3, 512)    262656      activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_190 (Add)                   (None, 3, 3, 512)    0           conv2d_587[0][0]                 \n",
      "                                                                 conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 3, 3, 512)    0           add_190[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 3, 3, 512)    2359808     activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)             (None, 3, 3, 512)    262656      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_191 (Add)                   (None, 3, 3, 512)    0           conv2d_590[0][0]                 \n",
      "                                                                 conv2d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 3, 3, 512)    0           add_191[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling2D) (None, 2, 2, 512)    0           activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 2048)         0           max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 200)          409800      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 200)          40200       dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 3)            603         dense_46[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 18,593,515\n",
      "Trainable params: 18,593,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_8 = ResNet_20_3((128,128,3),classes=3,conv_k_reg=0.001, conv_b_reg=0.001, dense_b_reg=0.01, dense_k_reg= 0.01)\n",
    "resnet_8.model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='acc')\n",
    "resnet_8.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define callbacks tosave model'''\n",
    "checkpoint_path = \"basic_mod/weights{epoch:04d}\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "80/80 [==============================] - 108s 1s/step - loss: 186.6242 - acc: 0.3515 - val_loss: 20.4516 - val_acc: 0.4214\n",
      "\n",
      "Epoch 00001: saving model to basic_mod/weights0001\n",
      "Epoch 2/40\n",
      "80/80 [==============================] - 114s 1s/step - loss: 19.9523 - acc: 0.4681 - val_loss: 18.8364 - val_acc: 0.5095\n",
      "\n",
      "Epoch 00002: saving model to basic_mod/weights0002\n",
      "Epoch 3/40\n",
      "80/80 [==============================] - 116s 1s/step - loss: 18.5057 - acc: 0.5507 - val_loss: 17.7797 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00003: saving model to basic_mod/weights0003\n",
      "Epoch 4/40\n",
      "80/80 [==============================] - 110s 1s/step - loss: 17.5309 - acc: 0.6087 - val_loss: 17.2579 - val_acc: 0.4357\n",
      "\n",
      "Epoch 00004: saving model to basic_mod/weights0004\n",
      "Epoch 5/40\n",
      "80/80 [==============================] - 109s 1s/step - loss: 16.8076 - acc: 0.6055 - val_loss: 16.5372 - val_acc: 0.5095\n",
      "\n",
      "Epoch 00005: saving model to basic_mod/weights0005\n",
      "Epoch 6/40\n",
      "80/80 [==============================] - 121s 2s/step - loss: 16.1792 - acc: 0.6098 - val_loss: 15.9580 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00006: saving model to basic_mod/weights0006\n",
      "Epoch 7/40\n",
      "80/80 [==============================] - 119s 1s/step - loss: 15.5919 - acc: 0.6481 - val_loss: 15.2850 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00007: saving model to basic_mod/weights0007\n",
      "Epoch 8/40\n",
      "80/80 [==============================] - 124s 2s/step - loss: 15.0412 - acc: 0.6763 - val_loss: 14.8418 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00008: saving model to basic_mod/weights0008\n",
      "Epoch 9/40\n",
      "80/80 [==============================] - 134s 2s/step - loss: 14.5717 - acc: 0.6881 - val_loss: 14.3735 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00009: saving model to basic_mod/weights0009\n",
      "Epoch 10/40\n",
      "80/80 [==============================] - 148s 2s/step - loss: 14.1448 - acc: 0.6750 - val_loss: 13.9479 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00010: saving model to basic_mod/weights0010\n",
      "Epoch 11/40\n",
      "80/80 [==============================] - 138s 2s/step - loss: 13.7354 - acc: 0.6960 - val_loss: 13.5657 - val_acc: 0.6262\n",
      "\n",
      "Epoch 00011: saving model to basic_mod/weights0011\n",
      "Epoch 12/40\n",
      "80/80 [==============================] - 144s 2s/step - loss: 13.3083 - acc: 0.7309 - val_loss: 13.2656 - val_acc: 0.6262\n",
      "\n",
      "Epoch 00012: saving model to basic_mod/weights0012\n",
      "Epoch 13/40\n",
      "80/80 [==============================] - 141s 2s/step - loss: 12.9490 - acc: 0.7302 - val_loss: 13.1468 - val_acc: 0.4905\n",
      "\n",
      "Epoch 00013: saving model to basic_mod/weights0013\n",
      "Epoch 14/40\n",
      "80/80 [==============================] - 143s 2s/step - loss: 12.6398 - acc: 0.7227 - val_loss: 12.6332 - val_acc: 0.6167\n",
      "\n",
      "Epoch 00014: saving model to basic_mod/weights0014\n",
      "Epoch 15/40\n",
      "80/80 [==============================] - 149s 2s/step - loss: 12.2805 - acc: 0.7430 - val_loss: 12.3299 - val_acc: 0.6048\n",
      "\n",
      "Epoch 00015: saving model to basic_mod/weights0015\n",
      "Epoch 16/40\n",
      "80/80 [==============================] - 136s 2s/step - loss: 11.9806 - acc: 0.7617 - val_loss: 12.1428 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00016: saving model to basic_mod/weights0016\n",
      "Epoch 17/40\n",
      "80/80 [==============================] - 110s 1s/step - loss: 11.7108 - acc: 0.7614 - val_loss: 11.9545 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00017: saving model to basic_mod/weights0017\n",
      "Epoch 18/40\n",
      "80/80 [==============================] - 103s 1s/step - loss: 11.3945 - acc: 0.7837 - val_loss: 11.6079 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00018: saving model to basic_mod/weights0018\n",
      "Epoch 19/40\n",
      "80/80 [==============================] - 101s 1s/step - loss: 11.1251 - acc: 0.8028 - val_loss: 11.2784 - val_acc: 0.6381\n",
      "\n",
      "Epoch 00019: saving model to basic_mod/weights0019\n",
      "Epoch 20/40\n",
      "80/80 [==============================] - 100s 1s/step - loss: 10.9825 - acc: 0.7689 - val_loss: 11.1633 - val_acc: 0.5905\n",
      "\n",
      "Epoch 00020: saving model to basic_mod/weights0020\n",
      "Epoch 21/40\n",
      "80/80 [==============================] - 99s 1s/step - loss: 10.6167 - acc: 0.8303 - val_loss: 11.0201 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00021: saving model to basic_mod/weights0021\n",
      "Epoch 22/40\n",
      "80/80 [==============================] - 100s 1s/step - loss: 10.4200 - acc: 0.8090 - val_loss: 11.2671 - val_acc: 0.4857\n",
      "\n",
      "Epoch 00022: saving model to basic_mod/weights0022\n",
      "Epoch 23/40\n",
      "80/80 [==============================] - 99s 1s/step - loss: 10.2819 - acc: 0.7802 - val_loss: 11.1044 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00023: saving model to basic_mod/weights0023\n",
      "Epoch 24/40\n",
      "80/80 [==============================] - 108s 1s/step - loss: 9.9900 - acc: 0.8233 - val_loss: 10.4393 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00024: saving model to basic_mod/weights0024\n",
      "Epoch 25/40\n",
      "80/80 [==============================] - 101s 1s/step - loss: 9.7336 - acc: 0.8547 - val_loss: 10.5845 - val_acc: 0.5690\n",
      "\n",
      "Epoch 00025: saving model to basic_mod/weights0025\n",
      "Epoch 26/40\n",
      "80/80 [==============================] - 102s 1s/step - loss: 9.5550 - acc: 0.8443 - val_loss: 10.0202 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00026: saving model to basic_mod/weights0026\n",
      "Epoch 27/40\n",
      "80/80 [==============================] - 101s 1s/step - loss: 9.3143 - acc: 0.8716 - val_loss: 9.9715 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00027: saving model to basic_mod/weights0027\n",
      "Epoch 28/40\n",
      "80/80 [==============================] - 103s 1s/step - loss: 9.0934 - acc: 0.8787 - val_loss: 9.7219 - val_acc: 0.5952\n",
      "\n",
      "Epoch 00028: saving model to basic_mod/weights0028\n",
      "Epoch 29/40\n",
      "80/80 [==============================] - 102s 1s/step - loss: 8.8997 - acc: 0.8949 - val_loss: 9.7887 - val_acc: 0.5524\n",
      "\n",
      "Epoch 00029: saving model to basic_mod/weights0029\n",
      "Epoch 30/40\n",
      "80/80 [==============================] - 109s 1s/step - loss: 8.7143 - acc: 0.8933 - val_loss: 9.9100 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00030: saving model to basic_mod/weights0030\n",
      "Epoch 31/40\n",
      "80/80 [==============================] - 108s 1s/step - loss: 8.5689 - acc: 0.8919 - val_loss: 9.9247 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00031: saving model to basic_mod/weights0031\n",
      "Epoch 32/40\n",
      "80/80 [==============================] - 106s 1s/step - loss: 8.4098 - acc: 0.8938 - val_loss: 9.2449 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00032: saving model to basic_mod/weights0032\n",
      "Epoch 33/40\n",
      "80/80 [==============================] - 102s 1s/step - loss: 8.2027 - acc: 0.9162 - val_loss: 9.4184 - val_acc: 0.5690\n",
      "\n",
      "Epoch 00033: saving model to basic_mod/weights0033\n",
      "Epoch 34/40\n",
      "80/80 [==============================] - 107s 1s/step - loss: 8.1050 - acc: 0.8941 - val_loss: 8.8058 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00034: saving model to basic_mod/weights0034\n",
      "Epoch 35/40\n",
      "80/80 [==============================] - 119s 1s/step - loss: 7.9536 - acc: 0.8903 - val_loss: 8.8762 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00035: saving model to basic_mod/weights0035\n",
      "Epoch 36/40\n",
      "80/80 [==============================] - 109s 1s/step - loss: 7.7543 - acc: 0.9224 - val_loss: 8.7585 - val_acc: 0.6048\n",
      "\n",
      "Epoch 00036: saving model to basic_mod/weights0036\n",
      "Epoch 37/40\n",
      "80/80 [==============================] - 121s 2s/step - loss: 7.5995 - acc: 0.9202 - val_loss: 8.5763 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00037: saving model to basic_mod/weights0037\n",
      "Epoch 38/40\n",
      "80/80 [==============================] - 119s 1s/step - loss: 7.4392 - acc: 0.9307 - val_loss: 8.6499 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00038: saving model to basic_mod/weights0038\n",
      "Epoch 39/40\n",
      "80/80 [==============================] - 112s 1s/step - loss: 7.3611 - acc: 0.9084 - val_loss: 8.4091 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00039: saving model to basic_mod/weights0039\n",
      "Epoch 40/40\n",
      "80/80 [==============================] - 107s 1s/step - loss: 7.1745 - acc: 0.9311 - val_loss: 8.3371 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00040: saving model to basic_mod/weights0040\n"
     ]
    }
   ],
   "source": [
    "'''fit the model'''\n",
    "training_object = resnet_8.model.fit(x_train,one_hot_y_train,epochs=40,batch_size=30, validation_split = 0.15,validation_batch_size=300,callbacks=[cp_callback])\n",
    "# resnet_8.train_test_predict(x_train,y_train,x_test[:5000],y_test[:5000])\n",
    "# plot_accs(training_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This overfits significantly. Let's increase conv_k and conv_b regularisation in order to overcome this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_512_512_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 61, 61, 64)   9472        input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 61, 61, 64)   0           conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling2D) (None, 30, 30, 64)   0           activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 30, 30, 64)   36928       max_pooling2d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 30, 30, 64)   4160        max_pooling2d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_204 (Add)                   (None, 30, 30, 64)   0           conv2d_631[0][0]                 \n",
      "                                                                 conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 30, 30, 64)   0           add_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 30, 30, 64)   36928       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 30, 30, 64)   4160        activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_205 (Add)                   (None, 30, 30, 64)   0           conv2d_634[0][0]                 \n",
      "                                                                 conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 30, 30, 64)   0           add_205[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 30, 30, 64)   36928       activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 30, 30, 64)   4160        activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_206 (Add)                   (None, 30, 30, 64)   0           conv2d_637[0][0]                 \n",
      "                                                                 conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 30, 30, 64)   0           add_206[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling2D) (None, 15, 15, 64)   0           activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 15, 15, 128)  73856       max_pooling2d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 15, 15, 128)  8320        max_pooling2d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_207 (Add)                   (None, 15, 15, 128)  0           conv2d_640[0][0]                 \n",
      "                                                                 conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 15, 15, 128)  0           add_207[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 15, 15, 128)  147584      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 15, 15, 128)  16512       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_208 (Add)                   (None, 15, 15, 128)  0           conv2d_643[0][0]                 \n",
      "                                                                 conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 15, 15, 128)  0           add_208[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 15, 15, 128)  147584      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 15, 15, 128)  16512       activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_209 (Add)                   (None, 15, 15, 128)  0           conv2d_646[0][0]                 \n",
      "                                                                 conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 15, 15, 128)  0           add_209[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling2D) (None, 7, 7, 128)    0           activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 7, 7, 256)    295168      max_pooling2d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 7, 7, 256)    33024       max_pooling2d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_210 (Add)                   (None, 7, 7, 256)    0           conv2d_649[0][0]                 \n",
      "                                                                 conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 256)    0           add_210[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 7, 7, 256)    590080      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 7, 7, 256)    65792       activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_211 (Add)                   (None, 7, 7, 256)    0           conv2d_652[0][0]                 \n",
      "                                                                 conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 256)    0           add_211[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 7, 7, 256)    590080      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 7, 7, 256)    65792       activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_212 (Add)                   (None, 7, 7, 256)    0           conv2d_655[0][0]                 \n",
      "                                                                 conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 256)    0           add_212[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling2D) (None, 3, 3, 256)    0           activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 3, 3, 512)    1180160     max_pooling2d_88[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 3, 3, 512)    131584      max_pooling2d_88[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_213 (Add)                   (None, 3, 3, 512)    0           conv2d_658[0][0]                 \n",
      "                                                                 conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 3, 3, 512)    0           add_213[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 3, 3, 512)    2359808     activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 3, 3, 512)    262656      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_214 (Add)                   (None, 3, 3, 512)    0           conv2d_661[0][0]                 \n",
      "                                                                 conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 3, 3, 512)    0           add_214[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 3, 3, 512)    2359808     activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 3, 3, 512)    262656      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_215 (Add)                   (None, 3, 3, 512)    0           conv2d_664[0][0]                 \n",
      "                                                                 conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 3, 3, 512)    0           add_215[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling2D) (None, 2, 2, 512)    0           activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 2048)         0           max_pooling2d_89[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 200)          409800      flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 200)          40200       dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 3)            603         dense_52[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 18,593,515\n",
      "Trainable params: 18,593,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_8_r = ResNet_20_3((128,128,3),classes=3,conv_k_reg=0.005, conv_b_reg=0.005, dense_b_reg=0.01, dense_k_reg= 0.01)\n",
    "resnet_8_r.model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='acc')\n",
    "resnet_8_r.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_r = \"basic_mod/weights{epoch:04d}\"\n",
    "checkpoint_dir_r = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback_r = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path_r,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "80/80 [==============================] - 118s 1s/step - loss: 596.0386 - acc: 0.3343 - val_loss: 73.6147 - val_acc: 0.3381\n",
      "\n",
      "Epoch 00001: saving model to basic_mod/weights0001\n",
      "Epoch 2/40\n",
      "80/80 [==============================] - 114s 1s/step - loss: 71.7373 - acc: 0.4098 - val_loss: 67.1363 - val_acc: 0.4595\n",
      "\n",
      "Epoch 00002: saving model to basic_mod/weights0002\n",
      "Epoch 3/40\n",
      "80/80 [==============================] - 113s 1s/step - loss: 65.9550 - acc: 0.4833 - val_loss: 62.9015 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00003: saving model to basic_mod/weights0003\n",
      "Epoch 4/40\n",
      "80/80 [==============================] - 108s 1s/step - loss: 61.9555 - acc: 0.5494 - val_loss: 59.5386 - val_acc: 0.5071\n",
      "\n",
      "Epoch 00004: saving model to basic_mod/weights0004\n",
      "Epoch 5/40\n",
      "80/80 [==============================] - 106s 1s/step - loss: 58.7567 - acc: 0.5696 - val_loss: 56.7700 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00005: saving model to basic_mod/weights0005\n",
      "Epoch 6/40\n",
      "80/80 [==============================] - 119s 1s/step - loss: 56.0733 - acc: 0.5897 - val_loss: 54.3352 - val_acc: 0.5667\n",
      "\n",
      "Epoch 00006: saving model to basic_mod/weights0006\n",
      "Epoch 7/40\n",
      "80/80 [==============================] - 115s 1s/step - loss: 53.7745 - acc: 0.5681 - val_loss: 52.1984 - val_acc: 0.5595\n",
      "\n",
      "Epoch 00007: saving model to basic_mod/weights0007\n",
      "Epoch 8/40\n",
      "80/80 [==============================] - 109s 1s/step - loss: 51.6527 - acc: 0.6346 - val_loss: 50.2892 - val_acc: 0.5738\n",
      "\n",
      "Epoch 00008: saving model to basic_mod/weights0008\n",
      "Epoch 9/40\n",
      "80/80 [==============================] - 113s 1s/step - loss: 49.7975 - acc: 0.6102 - val_loss: 48.6063 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00009: saving model to basic_mod/weights0009\n",
      "Epoch 10/40\n",
      "80/80 [==============================] - 111s 1s/step - loss: 48.0863 - acc: 0.6366 - val_loss: 46.9940 - val_acc: 0.5381\n",
      "\n",
      "Epoch 00010: saving model to basic_mod/weights0010\n",
      "Epoch 11/40\n",
      "80/80 [==============================] - 109s 1s/step - loss: 46.5785 - acc: 0.5854 - val_loss: 45.4526 - val_acc: 0.5762\n",
      "\n",
      "Epoch 00011: saving model to basic_mod/weights0011\n",
      "Epoch 12/40\n",
      "80/80 [==============================] - 100s 1s/step - loss: 45.0733 - acc: 0.6292 - val_loss: 44.1195 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00012: saving model to basic_mod/weights0012\n",
      "Epoch 13/40\n",
      "80/80 [==============================] - 103s 1s/step - loss: 43.7113 - acc: 0.6403 - val_loss: 42.8301 - val_acc: 0.5405\n",
      "\n",
      "Epoch 00013: saving model to basic_mod/weights0013\n",
      "Epoch 14/40\n",
      "80/80 [==============================] - 106s 1s/step - loss: 42.4159 - acc: 0.6486 - val_loss: 41.5924 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00014: saving model to basic_mod/weights0014\n",
      "Epoch 15/40\n",
      "80/80 [==============================] - 105s 1s/step - loss: 41.2200 - acc: 0.6549 - val_loss: 40.4173 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00015: saving model to basic_mod/weights0015\n",
      "Epoch 16/40\n",
      "80/80 [==============================] - 106s 1s/step - loss: 40.0724 - acc: 0.6574 - val_loss: 39.3954 - val_acc: 0.5548\n",
      "\n",
      "Epoch 00016: saving model to basic_mod/weights0016\n",
      "Epoch 17/40\n",
      "80/80 [==============================] - 108s 1s/step - loss: 38.9875 - acc: 0.6664 - val_loss: 38.3387 - val_acc: 0.5690\n",
      "\n",
      "Epoch 00017: saving model to basic_mod/weights0017\n",
      "Epoch 18/40\n",
      "80/80 [==============================] - 110s 1s/step - loss: 37.9432 - acc: 0.6831 - val_loss: 37.3525 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00018: saving model to basic_mod/weights0018\n",
      "Epoch 19/40\n",
      "80/80 [==============================] - 113s 1s/step - loss: 37.0058 - acc: 0.6633 - val_loss: 36.3809 - val_acc: 0.6095\n",
      "\n",
      "Epoch 00019: saving model to basic_mod/weights0019\n",
      "Epoch 20/40\n",
      "80/80 [==============================] - 115s 1s/step - loss: 36.0749 - acc: 0.6689 - val_loss: 35.5054 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00020: saving model to basic_mod/weights0020\n",
      "Epoch 21/40\n",
      "80/80 [==============================] - 129s 2s/step - loss: 35.1643 - acc: 0.6934 - val_loss: 34.6048 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00021: saving model to basic_mod/weights0021\n",
      "Epoch 22/40\n",
      "80/80 [==============================] - 120s 2s/step - loss: 34.2758 - acc: 0.6967 - val_loss: 33.7971 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00022: saving model to basic_mod/weights0022\n",
      "Epoch 23/40\n",
      "80/80 [==============================] - 126s 2s/step - loss: 33.4733 - acc: 0.7094 - val_loss: 33.0383 - val_acc: 0.5643\n",
      "\n",
      "Epoch 00023: saving model to basic_mod/weights0023\n",
      "Epoch 24/40\n",
      "80/80 [==============================] - 114s 1s/step - loss: 32.7037 - acc: 0.6858 - val_loss: 32.2029 - val_acc: 0.6190\n",
      "\n",
      "Epoch 00024: saving model to basic_mod/weights0024\n",
      "Epoch 25/40\n",
      "80/80 [==============================] - 113s 1s/step - loss: 31.9237 - acc: 0.6983 - val_loss: 31.4950 - val_acc: 0.6143\n",
      "\n",
      "Epoch 00025: saving model to basic_mod/weights0025\n",
      "Epoch 26/40\n",
      "80/80 [==============================] - 113s 1s/step - loss: 31.1848 - acc: 0.6868 - val_loss: 30.7917 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00026: saving model to basic_mod/weights0026\n",
      "Epoch 27/40\n",
      "80/80 [==============================] - 126s 2s/step - loss: 30.4417 - acc: 0.7066 - val_loss: 30.2168 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00027: saving model to basic_mod/weights0027\n",
      "Epoch 28/40\n",
      "80/80 [==============================] - 120s 1s/step - loss: 29.8050 - acc: 0.6929 - val_loss: 29.4570 - val_acc: 0.6143\n",
      "\n",
      "Epoch 00028: saving model to basic_mod/weights0028\n",
      "Epoch 29/40\n",
      "80/80 [==============================] - 110s 1s/step - loss: 29.0731 - acc: 0.7201 - val_loss: 28.7464 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00029: saving model to basic_mod/weights0029\n",
      "Epoch 30/40\n",
      "80/80 [==============================] - 114s 1s/step - loss: 28.4192 - acc: 0.7280 - val_loss: 28.1018 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00030: saving model to basic_mod/weights0030\n",
      "Epoch 31/40\n",
      "80/80 [==============================] - 124s 2s/step - loss: 27.7722 - acc: 0.7226 - val_loss: 27.4946 - val_acc: 0.6167\n",
      "\n",
      "Epoch 00031: saving model to basic_mod/weights0031\n",
      "Epoch 32/40\n",
      "80/80 [==============================] - 124s 2s/step - loss: 27.1966 - acc: 0.7175 - val_loss: 27.1780 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00032: saving model to basic_mod/weights0032\n",
      "Epoch 33/40\n",
      "80/80 [==============================] - 121s 2s/step - loss: 26.6281 - acc: 0.7107 - val_loss: 26.4022 - val_acc: 0.6190\n",
      "\n",
      "Epoch 00033: saving model to basic_mod/weights0033\n",
      "Epoch 34/40\n",
      "80/80 [==============================] - 118s 1s/step - loss: 26.0285 - acc: 0.7169 - val_loss: 25.7287 - val_acc: 0.6286\n",
      "\n",
      "Epoch 00034: saving model to basic_mod/weights0034\n",
      "Epoch 35/40\n",
      "80/80 [==============================] - 112s 1s/step - loss: 25.4243 - acc: 0.7411 - val_loss: 25.2319 - val_acc: 0.5952\n",
      "\n",
      "Epoch 00035: saving model to basic_mod/weights0035\n",
      "Epoch 36/40\n",
      "80/80 [==============================] - 114s 1s/step - loss: 24.8800 - acc: 0.7268 - val_loss: 24.6118 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00036: saving model to basic_mod/weights0036\n",
      "Epoch 37/40\n",
      "80/80 [==============================] - 122s 2s/step - loss: 24.3266 - acc: 0.7244 - val_loss: 24.0863 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00037: saving model to basic_mod/weights0037\n",
      "Epoch 38/40\n",
      "80/80 [==============================] - 116s 1s/step - loss: 23.7749 - acc: 0.7437 - val_loss: 23.6402 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00038: saving model to basic_mod/weights0038\n",
      "Epoch 39/40\n",
      "80/80 [==============================] - 110s 1s/step - loss: 23.2756 - acc: 0.7330 - val_loss: 23.1111 - val_acc: 0.6214\n",
      "\n",
      "Epoch 00039: saving model to basic_mod/weights0039\n",
      "Epoch 40/40\n",
      "80/80 [==============================] - 109s 1s/step - loss: 22.7437 - acc: 0.7489 - val_loss: 22.6577 - val_acc: 0.5952\n",
      "\n",
      "Epoch 00040: saving model to basic_mod/weights0040\n"
     ]
    }
   ],
   "source": [
    "training_object_r = resnet_8_r.model.fit(x_train,one_hot_y_train,epochs=40,batch_size=30, validation_split = 0.15,validation_batch_size=300,callbacks=[cp_callback_r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have a benchmark validation score of ~60%\n",
    "We could possibly tune the model and get a slightly higher score, but our training data has only 640 image after partitioning samples for validation and test set, which will limit the performance we can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train prediction percentage is {0.7106109324758842}\n",
      "test prediction percentage is {0.572139303482587}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-149-4ae7649b19aa>:78: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABDjUlEQVR4nO3deXiU1dn48e+ZyUZCErKQnSwQ1rATWRVEpIAbLljX1t2qdX9ra6ttba19/dW+toqKdati3RXUKi5AWAXEsC8JEEIggewhO1nn/P54EgzJJJkkk8zC/bmuXCQzz8zceYB7ztzPOfdRWmuEEEK4PpOjAxBCCGEfktCFEMJNSEIXQgg3IQldCCHchCR0IYRwEx6OeuHQ0FAdHx/vqJcXQgiXtG3btiKt9UBr9zksocfHx5OamuqolxdCCJeklDra3n1SchFCCDchCV0IIdyEJHQhhHATDquhW1NfX09OTg41NTWODsVl+fj4EBMTg6enp6NDEUL0MadK6Dk5Ofj7+xMfH49SytHhuBytNcXFxeTk5JCQkODocIQQfcypSi41NTWEhIRIMu8mpRQhISHyCUeIs5RTJXRAknkPyfkT4uzldAldCCGcWtEh2PU+NDY4OpI2JKELIYStLBb46BZY/gt4dTYc3+boiM4gCb0H+vfv7+gQhBB9ac+HkL8HzrkDKgvg1Tmw4hGoKXN0ZIAkdCGEsE19DaT8BSLHw4K/wb1bYfIdsPVVeGEy7FsOtuwAV1cFp072SohONW2xpT/9dx/7T5Tb9TlHRQXwx0uT2r3/N7/5DXFxcdxzzz0APPHEEyilWL9+PSdPnqS+vp6//OUvLFy4sNPXqqysZOHChVYft3TpUv7+97+jlGLs2LG8/fbb5Ofnc9ddd5GZmQnAkiVLmD59uh1+ayGEXWx9BcqyYeGLYDKBTyBc9AyMuxb++yB8dDMkzoWL/w5B8UZyLz0K+fsgby/k7zW+L8mEmY/ABY/ZPUSnTeiOcO211/Lggw+eTugffvghX3/9NQ899BABAQEUFRUxdepULrvssk5nk/j4+LB8+fI2j9u/fz9PPfUU3333HaGhoZSUlABw//33M2vWLJYvX05jYyOVlZW9/vsKIWx06iRs+D9IvBAGzzrzvuhJcMca2PovSHkKXpwKEWOgIA3qKn48LngwhCfB2GtgyAW9EqbTJvSORtK9ZcKECRQUFHDixAkKCwsJCgoiMjKShx56iPXr12MymTh+/Dj5+flERER0+Fxaa373u9+1eVxKSgqLFi0iNDQUgODgYABSUlJYunQpAGazmcDAwN79ZYUQttvwrFEnv/BP1u83e8C0X8KohbDyj1CWA+OuMRJ4+BgIGwnevX/NzWkTuqMsWrSIjz/+mLy8PK699lreeecdCgsL2bZtG56ensTHx9u0cKe9x2mtZa64EK6kNBu+/xeMuw4iRnd8bGAMLHq9b+KyQi6KtnLttdfy/vvv8/HHH7No0SLKysoICwvD09OTNWvWcPRou62Iz9De4+bMmcOHH35IcXExwOmSy5w5c1iyZAkAjY2NlJfb9/qBEKKb1jxl/Dn7d46NwwaS0FtJSkqioqKC6OhoIiMjueGGG0hNTSU5OZl33nmHESNG2PQ87T0uKSmJxx57jFmzZjFu3DgefvhhAJ577jnWrFnDmDFjmDRpEvv27eu131EIYaO8PcYioim/gAGDHB1Np5S2ZZpNL0hOTtatdyxKS0tj5MiRDonHnch5FMJO/nMV5KTCAzuhX5CjowFAKbVNa51s7T4ZoQshhDWZ6yBjFcz8ldMk887IRdEe2rNnDz/72c/OuM3b25vvv//eQREJcZYrOw5LLwOTB8ROhdhpMGiKMTfc1gkJFgus/AMEDjJWhboISeg9NGbMGHbu3OnoMIRwH+UnYMtLUFsJC/4feHjb/tjaCnjvGqjIN5L53uWw7U3jvv4REDulKcFPhtBh4O1v/Xn2LYPcnXDFv8DTp6e/UZ+RhC6EcA6FB2HTc7DrA9AW0I1QkQc/XQoeXp0/vrEBPr4N8vfDDR8ai4AsFihMg2Ob4dgW42v/Zz8+pl8wBMXBgDhjBN/8/eo/G/PHx/y0137d3iAJXQjRdTVlsP1tSDgPIsf17LlyUmHjPyD9S2M0PulmmH4vZKyGLx82ltRf/WbnSf2b38Ghb+DiZ41kDsYS/fAk4+uc243bynKM1zx5BE4ehZNZkLfbeH1L/Y/Pd+MnxuNdiCR0IYTtGuog9XVY9zc4VQImT7jwCZh6T9eSn9ZGwt74Dzi6EXwGGP1NpvwC/IxV1JxzmzFSX/Er+PgWI6mb29krd8vLxtL7afcaj+tIYIzx1ZqlESpyjSRvaWi7xN8FSEIXQnTOYjHqyqv/bDScSphlzP74/l/w7WOQuQYuXwL9wzp/rqObjQuOOVshIBrm/RUm3mR9afzkO4zk/9Uj8PGtsOiNtkn9wFfw9aMw4hKY++fu/44mc/vJ3kW41ueJXlZaWspLL73U5cdddNFFlJaW2j8gIZxB5jpjM4dPbgPvAKMU8fPPIGEmXPMfo8SRtRGWzDBG3e0pPADvXQ//nm90Lbz0Obh/p9EDpaM+J1PuhPlPQ9rn8MntZ+4UdGKnkeijxsOVrxhJ+SwmI/QWmhN6c7fFZo2NjZjN7f9DWbFiRW+HJoT9aA1H1sOWJUY7V98g4+Kgb0iLr2CjDLL7A8hYaUzfu+JfxkXClqUVpYwSR+w0I+H/50qYfh9c8Icfa97lubD2f2HH2+DpBxf83ijRePnaHvPUu42SyLePgTLBla9CZT68d60R+3Xvg5efXU+TK3LehP7Vo8ayW3uKGAMLnm737kcffZTDhw8zfvx4PD096d+/P5GRkezcuZP9+/dz+eWXk52dTU1NDQ888AB33nknAPHx8aSmplJZWcmCBQs499xz2bRpE9HR0Xz22Wf069fP6uu9+uqrvPLKK9TV1ZGYmMjbb7+Nr69vu73RrfVRF8Jm9TWw9+OmRL4XfEONNq615VBdbJRSqovP3H3HZwDMfRIm39nx9L3wUXBHCnz7OGxaDEc2GCPw9C9g84vQWG88x8xHfqyRd9X0e42ZLyv/YPxcdMiY2njbN+DfcffTs4XzLv13QELPysrikksuYe/evaxdu5aLL76YvXv3kpCQABiNtIKDgzl16hTnnHMO69atIyQk5IyEnpiYSGpqKuPHj+enP/0pl112GTfeeKPV1ysuLiYkJASAxx9/nPDwcO677z6uueYapk2bxoMPPni6N3pOTg5XXnnlGX3Um1vvtiZL/8UZKgsg9Q344TWoKoSwJJh2D4xeZD1JN9Yb/b+ri40at09A114v7Qv4/N4fd+VJuhLm/N7oB24PG/8Bq54AZf5xeuJZpKOl/zaN0JVS84HnADPwmtb66Vb3PwLc0OI5RwIDtdYl3Y66g8TbVyZPnnw6mQM8//zzLF++HIDs7GwOHTp0OiE3S0hIYPz48QBMmjSJrKysdp9/7969PP7445SWllJZWcm8efMA673Rly5darWPuhBWWSyQ/T3s+I+xD2ZjHQydZyTyhFkdr5g0exoXN225wGnNyEsgagJ8/zIkXW5sAGFP5z4EfmHQb8BZl8w702lCV0qZgReBuUAO8INS6nOt9f7mY7TWzwDPNB1/KfBQj5K5k/Dz+7Emt3btWlatWsXmzZvx9fXl/PPPt9oX3dv7x1VtZrOZU6dOtfv8N998M59++injxo3jzTffZO3ate0eK33URacsFjieCnuXGYtnKk6Apy9M+JlRgw4d2nexBEbDT57sveefcEPnx5yFbJnlMhnI0Fpnaq3rgPeBjjbVvA54zx7B9TV/f38qKiqs3ldWVkZQUBC+vr6kp6ezZcuWHr9eRUUFkZGR1NfX884775y+3Vpv9Pb6qAs3d/IoHN9mrKIsPwE15Ubibqa1sUjmm8fgn2Pg9bnGPPGoCXDla/Crg3DJs32bzIXD2FJyiQayW/ycA0yxdqBSyheYD9zbzv13AncCxMbGdinQvhASEsKMGTMYPXo0/fr1Izw8/PR98+fP5+WXX2bs2LEMHz6cqVOn9vj1nnzySaZMmUJcXBxjxow5/Wby3HPPceedd/L6669jNptZsmQJ06ZNO91H3Ww2M2HCBN58880exyCcWOZaePtK40Jga179jS/daNTFTZ5G+WHOH2D4fGMDY3HW6fSiqFLqamCe1vr2pp9/BkzWWt9n5dhrgBu11pd29sLSD733yHl0Ayez4JXZRh37wiegrspoPFVbAXWVxuyO2nLjAubgWTD8IqOmLNxeTy+K5gAtt+qIAU60c+y1uGi5RQinUVcF799ojL6vfRdChjg6IuEibEnoPwBDlVIJwHGMpH1964OUUoHALMD6HL2z2C9/+Uu+++67M2574IEHuOWWWxwUkbDZtjdh9ZNGq9WhF0LiXGP6a29doNYaPrvXmCd+w8eSzEWXdJrQtdYNSql7gW8wpi2+obXep5S6q+n+l5sOvQL4Vmtd1ZOA3HE2x4svvthnr+WodQVux2KBVX+ETc9DzGSoqzD6mKz+s9FXO/FCI8EPnm2UOiyNxsKcokNQdLDpz6bv+4fBZS9AjA3T9zY9b/RMufAJ4/mF6AKnWlh05MgR/P39CQkJcbuk3he01hQXF1NRUXHG/HnRRXXVsPxOSPsvJN8GC/4GZg+jN3fGamMp/OEUY0WlMht9tMuyjbnezXxDjVF9yBA4vMbo4jfrN3De/xjPZU3GKnjnahi1EBb9u/c+BQiX1lEN3akSen19PTk5OVbndwvb+Pj4EBMTg6dnO21GRccqmvqDnNhhdAGcerf1xNrYYMz5PrQSig5AUIKRwEOHGVMEfVss/DpVCiseMRb4xJxj9ERpXUopPmw0wAqIgdtXSl8S0S6XSehCOFT+Pnj3GmPJ+1Wvw4iL7Pv8ez+BLx4y3gzmN7WMVcqYsfLahVCZB3esgWD5dCXa11FCl/a5wvU1NkBJprETTWWhUQqpP3XmApzOHFoFr88zNja45Sv7J3OA0VfB3ZshJhn++wC8f73RZ+XTu41R/qJ/SzIXPeK83RaFsEVlgbH4Jr+dRm4mDzB7GX28fYN/bA3bslXsqVJY/wyEjYLrPzCWrfeWwGj42adGn5NVT8A/x0LDKfjJUzBkdu+9rjgrSEIXrqv0GCxdaFysnP+00beksc74aqg1Ft001hrf11YYpZTqEihIN74/VWJscQZG46pFb3S80YK9mExGk6zB5xsj9fAkY5MHIXpIErpwTYUHYOnlUF9l7J4zaHLXn8NigZpSI9kPiO37WSXho4wLoELYiSR04XqOb4f/XGWUU25eARGju/c8JlNT+UVaEQv3IBdFhWvJ2ghvXWY0prr16+4ncyHckCR04ToOfG2MzAOijG3HZFm8EGeQhC5cw+4PjWl+YSONaYUBUY6OSAinIzV04dwKD8KWF2HbWxB/rtF9sKt7XApxlpCELpyP1kavlC1LjL4pZm9IvtVYit/RzvNCnOUkoQvnUX/KKK1sWQKFacZGwLMfM5K5X6ijoxNuQmvNl3tyGT9oADFBvo4Ox64koQvHqSk3Ws4275u5/S1jwU/4GLh8ibFU3sO78+cRogs2Hy7m3nd3YDYp5idFcOu5CUyKC3J0WHYhCV30Pq1h/6dGB8OTWUYCLz0Kp062OEjB8AUw9R6jVi6tY0Uv2XS4GLNJccv0eD5IzT49Wr/t3AQWjI7Aw+y6c0UkoYvet+l5WPkHo6dK4CAIioPoiTAgzvh+QJzRlKqfe4yShHPbklnM6OhAHr9kFA/NHcYn23N4Y+MR7ntvB1GBPvx8ejzXnRNLoK/rtaCWhC561/7PjGSedCVc9RqYzI6OSJzFqusa2JVTym3nDgbAz9uDn0+L58YpcaSkF/DGd0d4+qt0Xl2fyaqHZxHk5+XgiLvGdT9bCOeXkwrL7jS2cLt8iSRz4XDbjp6kvlEzbUjIGbebTIoLR4Xz7h1Tef2mZIqr6vjucJGDouw+Seiid5w8auz84x8B170n0w2FU9h8uBgPkyK5g4ugM4cNxM/LzJbM4j6MzD6k5CLaV3/K2BqtedNjv1CYcGPnM09OlcK7PzXa2F6/QqYcCqexObOYsTGB+Hm3n/o8zSbOSQhm82FJ6MJV1VYYW6QVHmxK4AeNfuO02qLwu3/CBX8wphSarHzAa6yHj26C4gz42XIYOKwvoheiU1W1DezOKeMXMwd3euzUwSGsPVBIQUUNYf6u8+lSErowphV+cjsc/NrYJCIk0dgmbfz1xobHIUON245thpV/hGW3w+bFMPfPxiYNLZ/ny4chcy0sfAkSZjrqNxKijR+ySmi0tK2fWzNtsHHMlswSLhvnOn2DJKG7i4o8o2Y940FIurxrj923zEjmF/4Jpt9vfeQNkDgHBs+GPR9BypPGbkFD5sDcP0HEGPjuOdi+FM77FUy4oae/kRB2tSWzBE+zsmkRUVJUAP29Pdh8uFgSunCAr35tLNz57JcQORaCO/9YCRhbsq34NURNhOn3tZ/Mm5lMMO4aGLUQfngV1v8dXj4Phs6FQ98apZjZj/X89xHCzjZnFjMuZgC+Xp2nPQ+zickJwXzvYhdGZZaLO0hfYcz3nnynsYvPx7dCQ51tj/3mMWMbtssWd21aoaeP8QbwwE7jz8x1MGiqUWrp7E1BiD5WUVPP3uNlNpVbmk0bHEJmURX55TW9GJl9yf88V1dbASt+ZexYP++vsPAFY6Se8mTnj81YDbveNco03d35p18Q/ORJ+J90uOlzmZ4onFJq1kkaLZqpg21P6FNP19FdZ5QuCd3VpfwFyk/Apc+D2RNGXgrJtxnL7TNWt/+42kr44kHjgufMR3oeh2+wNNISTmtzZjFeZlOXmnCNigrA38fDpaYvSkJ3ZTnb4Pt/weQ7YNA5P94+7ykYOBKW3wWVBdYfu+avxrTEyxbLqFq4lEaL5pNtOV0aOW/JLGZ87AB8PG0vK5pNiikJwWyWEbrodY318N/7wT8SLvj9mfd59oOr/w215UZSt1jOvD9nG3y/xBjJx03ru5iF6KGtR0q4ZPFG/uejXdz77g5q6hs7fUx5U/28K+WWZlMHh3C0uJoTpae6E26fk4Tuqja/APl74eK/W9+SLWwkzP9fOLzaOLZZQx18fq/xRnDhE30WrivLOVmN1rrzA93MidJT7D1eRlVtg6NDIa+shvvf28FP/7WZsuo67rsgkaLKWt7feqzTx27NLMGif5xb3hXNF1FdpY4u0xZdUUkmrH3aqJePuLj94ybdAofXwOo/QfwMiJ5kzBUv2A/XfSB7c9pgTXoBt7z5A7+7aAR3zhzi6HDaqKlv7FIZwRYVNfUsTsngjY1HaLAYb2ThAd7Eh/gxeKAf8SF+JIQa3yeE9sds6r3e9TX1jby+8QgvrsmgwaK5f85Q7p41BB9PE1syi3l5XSbXTYnF26P9c7AlsxgvDxMTYgd0+fVHRgQQ2M+TLZnFXDkxxqbH1DdaMCuFqRfPS3skoTuTj26BY1tg8u1GMvYNbnuM1vDFQ0Zv8QV/6/j5lILLnocl2+Hj2+Cq12H934xWtsPn987v4GbebRoB/r+vDzAxNojkeCt/J33MYtGkpBfw+sYjbDlSzPJ7ZjB+0AC7PO+yHcd5+qt0iqtquSZ5EOcNHUhWcRVHiqrIKqri2335FFf9OCU22M+L84cNZPaIMGYOG0hgP/v0ENdaszqtgCe/3M/R4mrmJYXz+MWjGBT845Zx910wlJ+/sZVPth3n+imx7T7X5sxiJnaxft7M1MU6utaan73+PWaT4u1bp/R5UpeE7iyObDBWbAYPgdV/hnXPwLhrjR18WvZD2f2BsbT+4v+DABtWsPULMvqQv3kR/Hs+ePl1/kYgACiqrGVNegHXTY5l0+Ei7n13B1/efy4h/e03m+fu/2wjo6CS2SPCmD08jOT4IDzb2TGnqraBj7fl8O/vjpBVXE1koHExe/3Bwh4n9N05pfzx833sOFbKhNgBvH5TMuPaec6yU/VkFVVxqKCS7zKKWHOggGU7jmM2GaswLxgRxgUjwhga1h/VzZ2nXttwhKdWpJEY1p+3b5vMeUMHtjnmvKGhjBs0gJfWZnB1cozV81ZaXcf+3HIenNP9nkLThoTw7f58ck5Wd7oH6bqDhWzJLAHgg9Rsrpvc/htNb5CE7gwsFvj2cQiIgbu/g5IjsOUl2PkubPs3JM6FafdAxFj4+rcwaApMutX254+bBuf/FtY8BfOeh/5t/3OItj7dcZwGi+bWGfHcMCWWK5ds4qEPd/HmzefYZeRVUFHDV3vzGBTcj39/d4RX1mfi7+PBzKHGiPf84QMJ7e/N8dJTLN2UxXtbj1Fe08D4QQNY/JPhzB8dwSXPb2Tb0ZOdv1g7iipreebrA3y4LZsQP2/+7+pxXDEhusPfL7CfJ+MGDWDcoAEsmhRDo0WzM7uUlPR8UtILefqrdJ7+Kp3YYF+W3jqZ+FC/Lse1Oj2fkZEBfH7vjHbf4JRS3Dc7kduXpvLZzhMsmtS2JLL1SAlaw9TB3f9kNbVFX5dFk9pP6FprFqdkED2gH9FB/Xj6q3Tmjgon1I4DgM5IQncGez+B3J1w+cvGDJXwUcYCoQufgNQ3YOur8PYV4OUPDTVw6XNdX4058xFjWX6I89WBnZHWmo9Scxg3aABDw/0B+OOlo3hs+V5eWpvBvRcM7fFrrE0vBOBfNyYTG+LLxkNFpKTns+ZAIV/uyUUpGBbmT0ZhJQDzR0dw27kJTIz9cS71xLggvth9AotFd/lNZk16Afe/v4NTdY3ccd5g7rsgEX+frpdMmkfmk+KCeGTeCHLLTvH13jz+9N/9rD9U2OWErrVm/4lyLh4b1W4ybzZnZBgjIwN4aU0GV0yIblPP35xZjLeHifHdqJ83Gx7uT5CvJ5sPF1t902j5WtuOnuTJhUlMGxLKgufW89cv03j2mvHdfu2ukoTuaPU1RoklYgyMvebM+/xCYdavYcYDsHeZMVofeakxg6WrlHLbZL7j2Em+yygiruliXUKoX4f9rm2x93g5B/Ir+MvlP66gvX5yLFuPlPDsyoNMjAti+pCe9XlPSS8gMtCHkZH+KKWYPzqC+aMjsFg0+06Uk5JewJbMYm4bnsBN0+OJHtCvzXNMigviva3HyCisZFjTG4+tlqw9TJCvF8vvOYfEsP49+l1aigzsx83T43lu9SH2nyjv8uNPlNVQXtPAqMjOfx+lFPddkMg972znyz25bRppbcksYVJcUIcXTTtj1NFDOp3psnh1BmH+3lydPAgfTzN3zRrC4pQMFk2KYXpi3+wJIAnd0ba+AmXHYOFn7Y+6Pbxh/HXGlziD1ppHP9nDgfyKM24P8/cmPtSPwaF+xIf6sXB8FJGBbRNiez7alo23h4lLWyQIpRR/vWIMe4+X8cD7O/ny/nO73Su7tqGRDYcKWTghuk2d2WRSjIkJZExMIA/Q8SeB5pWP246e7FJCP1XXyM7sUm6eEW/XZN5MKUVSVAD7c7ue0NOa3gRGRto2C2t+UgRDw/rzQsohLhkTefqTysmqOtJyy/mfuT3vyT9tSAhf78sju6T6jAuzzVKzSticWczjF488ffH1l7MT+XzXCR7/dC9fPXhej95UbCXz0B2pusToVpg498y+4sJme46XcSC/gt9fMoqvHzyPJTdM5NfzhzNr2EAsFs2qtHye/iqdm9/4gYZGS+dPiDFV7rOdJ5iXFNFm1oaftwcv3TCJipp6HnhvJ42W7s1P33qkhKq6RuaMCOvW45vFh/gS4udFalbX6ujbj52krtHSrbnZthoVGUB6XgX1Np73ZmlNbwIjbEzoJpPi3gsSOZhfybf7807f/v0RY0TdlYZc7Wl+jvbaACxOySDEz4sbpsSdvs3H08yTC0eTWVTFy2szexyDLSShO9L6Z6CuwtgoQnTLR6k5eHuYWDQphhERASwYE8k95yfyzNXj+Pju6aQ+PpcXr5/IgfwK3v8h26bnXJWWT9mpeq5Otl4vHR7hz18uH8PmzGKeW3WwW3GvTivA28PU47KNUoqJcUFsP9a1hL4lsxizSZEcb3tvk65KigqkrsFCZmFVlx6XlldOXIgv/btQNrt4TCTxIb4sTsk4vQhsS2YJ/TzNjI0Z0KXXt2ZoWH9C/Lysll1255Sy7mAht583mH5eZ47CZw4byKXjonhxbQZHirp2HrrDpoSulJqvlDqglMpQSj3azjHnK6V2KqX2KaXW2TdMN1SSaVzsnHCjcRFUdJkxkj5udSTd0kVjIpicEMw/Vh6kvKa+0+f9KDWHqECfDpPtokkxXD0phsVrMlh3sLBLcWttzCOfkRjaJgF0x6S4II4UVVFcWWvzYzYfLmZ0dGC3LoLaalSUMcLed6KsS49Ly61gZETXFr15mE3cMzuRfSfKWXPA6F+0+XAxyfFBeHn0fNyqlGLq4BA2Zxa3WTW8OCWDwH6e/GxanNXH/v7ikXibTfz+0729vuK4099UKWUGXgQWAKOA65RSo1odMwB4CbhMa50EXG3/UN3M6j8b3RFlM4huW7k/n/KahnZH0s2UUvz+4lGUVNfxYkpGh8fmldWw4VAhV02K6XQF5J8XjmZYmD8PfbCTChveKJodLqziWEk1F/Sw3NKsuY6+/VipTcdX1zWwK6e0V8stAIND/fD2MHXpwmh1XQNZxVU2189bumJCNNED+vH86gyKK2s5kF/Rrf4t7Zk6OJjcshqOlVSfvi0tt5yV+/O5dUZCu58owgJ8+PX84WzMKOLzXSfsFo81trx1TQYytNaZWus64H1gYatjrgeWaa2PAWit22nxJwDI/gH2LTc2hvCPcHQ0dvG/X6Xx7MqDXa6X9sRH2zofSTcbExPIVRNjeOO7Ixwtbv+j7yfbc7BoOpye1qyfl5mnrxpDSVUdy7YftznulPR8ALsl9DHRgXialc3z0bcdPUl9o+7R3GxbeJhNjIjwZ18XEnp6XgVaw0gbZri05mk2cff5Q9iZXcqzK41SmD0TurU6+gtrMujv7cHN0+M7fOz1U+IYFxPIk1/sp6za9jf/rrIloUcDLYuPOU23tTQMCFJKrVVKbVNK/dzaEyml7lRKpSqlUgsLu/Yx1W1obSwi8gsz9u90A6XVdbyyPpPnVx/ip//aTHaLEUxvyS07ZfNIutkj84bjaTbxvyvSrd6vtebjbTlMTggmLsS2udMTYoMYN2gAb23OwmLjBdLVaQWMiPAnyso0xO7w8TSTFBXIdhsT+ubDRv38nD5oYzAqKpD9ueU2lxr2d3GGS2tXJ8cQHuDNO98fw9fLzNiYwG49jzVDBvYntL/36TYAGQUVrNiTy03T4wj07bh0ZTYpnrrCePP/2zfW//3Zgy0J3dr/ltZ/Ox7AJOBiYB7we6VUm7lCWutXtNbJWuvkgQPP0tWK6V9A9haY/Tvwtv90MUf4LqMYreHu84eQkV/JRc9v4Mvdub36msu2H0fbOJJuFh7gw92zhvD1vjyrF7e2HT3JkaIqru7CcwLcPD2OzMIqNmYUdXpsWXU9qUdPMmekfUbnzZLjgtiVU0pdQ+efkLZkFjM2JrDHc/VtMSoqgLJT9Ry3sf1sWm45/j4exAR1783O28PML5qaqCXHB3e6MKkrjDp6MFua6ugvrjmMj4eZ2861bf/e0dGB3DIjgXe3HuvyRWxb2fLb5gCDWvwcA7QuBOUAX2utq7TWRcB6YJx9QnQjjfWw8o8QOhwm/MzR0djNhkOF+Pt48D9zh7HigfMYMrA/v3x3O79bvsemftVdZazizO7SSLrZHTMHExXow5Nf7G8z5fCj1Bx8vcxcNCayS8950ZhIQvt78damrE6PXXeokEaL5oIR4V16jc5MiguitsHS6QXIqtoGdueU9Xr9vFlS04VRW+voabnljIwI6HYPGIDrJscyKjKgzSIje5g2JIT88lrWHizks53HuXFqLMF+XjY//qG5w4gI8GF1Wr7dYwPbEvoPwFClVIJSygu4Fvi81TGfAecppTyUUr7AFCDNvqG6uFOl8N8HoeSwMU3R7B5rurTWbDhUxPQhIXiYTQwK9uWju6Zx16whvPv9MS57YSMHWy366anUoyfJKq7u8kgajPLEbxaMYN+Jcj7ZnnP69uq6Br7ck8tFYyK7PHL19jBz/eRYUg4UcKy443JTSlo+wX5edumO2NLEFguMOpJ69CQNFm2Xudm2GBHhj1LYVEe3WDTpeRWnZ8d0Vz8vMyseOK9Ln95s1fxG+KsPd+FhNnHHTNtG5836e3vw5f3n8ci8EXaPDWxI6FrrBuBe4BuMJP2h1nqfUuoupdRdTcekAV8Du4GtwGta6729ErGrsVhg+9uweJKxIfO0e2HYPEdHZTdHiqo4XnrqjG54nmYTjy4YwdJbJ1NSVcdlL2zkva3H7DZl66PU7G6NpJtdNi6KCbEDeOabA6c3b/h6bx6VtQ3depMAuGFqHGalWLo5q91jGi2atQcLOX/4QLv3EA8P8CEmqF+nH+U3Hy7G06y6tLdmT/h6eZAQ6mfTitFjJdVU1zV264JoX0kI9SPM35viqjquO2dQt1YKd2VE31U2FZi01iu01sO01kO01k813fay1vrlFsc8o7UepbUerbX+Zy/F61pO7IDX5xo7BAUPhjvXGvt99uDjpLPZcMioG8+00t505rCBrHjgPM6JD+a3y/bwn+87312mM9V1DXy5u3sj6WZKKX5/ySgKK2pZsvYwYJRb4kJ8mZzQvQuF4QE+zB8dwYep2VTXWd/hZ8exk5RW1zPHzuWWZpPigth29GSHb5ybM4sZFzMAX6+++4SYFBVoU8mleYVody+I9gWlFNOHhOBpVvxilvP1RpKVor2husQor7wy29iI+fKX4dZvILL7lxUO5lewaMkm3vzuiP3ibFJYUctvPt7NoiWbbLqo1tKGQ4XEhfgSG2K9rWiYvw9v3TKZc+KDeDElg9qGntXUV+zJo6qusdsj6WYTY4NYOD6KVzdksiWzmM2ZxSyaGNOj2u3N0+Mpr2lg+Q7rUxhXpxfgYVKcN6x3GjVNigsiv7y23QuQFU17a/ZVuaXZqMgAjpeeorS6rsPj0nLLMSm63GSsrz26YCTv3THVbrOU7EkSuj011BntbhdPhO1LYerdcF+q0VSrq+1um2iteff7Y1y6eCOpR0/y6oYjditd1DdaeG1DJhf8fS0fpGaTevRkl1Y91jVY2Hy4mPOGdpygTCbF/XOGkldew8fbcjo8tjMfb8vu0Ui6pV/PN+qYt7+VilJwVQ/fJCbFBZEUFcBbm7Ks/h2lpBUwOSGYgF5anTmpkzp6atZJGi3arnOzbWHrhdH9ueUMHtjf7lvq2VtEoI9T7FxljSR0eyg8aMwt/8coY3u4sFFw1wZjk2af7s+DLTtVz73v7uB3y/cwOSGY3y4YwfHSU+zILu1xyBsPFbHguQ385cs0JsYF8e1DMwnx8+LTdkaX1uw4dpKqukbOTex8Cuq5iaGMHzSAJWsPd3vx0bHiamOTgR6OpJtFD+jHL2YOprK2gXMTQ3s84lJKcdP0eA7mV7bZsiy7pJoD+RV2W0xkzfBwf/y8zO0m9C2ZxXiZTWf0U+8LzRc5O6ujp+VWOHW5xRVIQu+uuirY8Q68Pg9ePAe2LDF2Err+I7j5SwhP6tHT7zh2kouf38A3+/J4dMEI3rplMtdNicXLbOKLXd2f451dUs1db2/jxte/p67Bwms/T+bNW85hWLg/l46LYmVavk39TgA2ZhRhNimbPsIrpbh/TiI5J0916U2jpY+359hlJN3SL2YNYdawgdxlp3roZeOiCPL1bDOFsbm/SG8mdA+zsZFDewl9c2Yx4wcNsEv/mK4I7e9NeIB3hyP0smpjrrozXxB1BZLQuyp3F/z3Afj7cPjsHqguMqYhPpwG174Dw37So4ueFovm5XWHufrlzQB82DQF0GRSBPh4Mmv4QL7cc8LmVYnNGhot/GPlQS58dh3rDhbyyLzhfPvQTC4cFX56tHv5hGjqGix8vSevk2czrD9UxPhBA2zeGHj28DCSogJ4ae3hLredtVg0n2zLsctIuiU/bw/eunUyM+y0AYGPp5lrJ8eysmkPymYp6QUkhPoxeGDvLiabFBtEWm756dk7zcqb6udT+7h+3mxUZECHUxfT8spPHye6TxJ6VxQfhlfnwK4PjJ2Dbvka7k01dhTq3/ORV2FFLTf9eytPf5XOT5LC+fL+89p8PL50XBT55bX8kFXSpef+IDWb51YfYu6ocFJ+NYtfzk5sU6scFxNIQqgfn+7sfARdWl3H7pzSTuvnLTXvLnOkqIovdnetSdHmzGKOl57qlbnF9nbjVKPr3ttbjgLGzJxNh4t7dXTebGJcEBYNu1qV5X44UoJF02cLilpLigoko7Cy3YVmzTNcJKH3jCT0rti7DCz18MstcMUSY/NlO01BPJhfwcIXNrL1SAl/vWIML14/0erId86IMHw8TXzRhaX1Wmve2pRFUlQAi6+b0O7OPUopFo6PYnNmMbllHS/Vbl7u35WEDvCTUREMC+/PCykZXfqU8VFqNv4+HsxLcv5mZtED+jEvKYIPfsimpr6R7zKKqWuw9HgzC1tMiA1CqbYXRjcfLsbLw8SEHuyt2ROjogJotOh2F5ml5ZYT4ufFQP++21DZHUlC74p9y2HQVAiKt+vTbjpcxFVLNtFg0Xxy93SunxLb7kU/P28P5owI56u9uTbvwLP5cDEH8yu5aXp8pxcTLx8fjdbw+c6OR9AbMwrx9/ZgXBc3DzCZFL+cncihgkq+2Wdbaae8pp6v9uZx2bgop58B0eym6fGUVtfz2c7jpKTn4+/t0SczIwL7eTIszJ/UVgl9y5FiJsYOcNj562ymS/MFUXtc7D6bSUK3VeEBKNgHo6+069N+tvM4N72xlfAAH5bdM53R0Z3PirlkbCRFlXVsybSt7PLmpiyCfD1t6m0RH+rHhNgB7c6lBmPEv/5gEdMTjeX+XXXJ2CgSQv3O2F2mo9cy5q9buDp5UIfHOpMpCcGMiPDnzU1HSUkvYOawgXbZaMEWzTsYNX8CKquuZ9+J8j6frtjSoCBjByJrdfSGRgsH8ivkgqgdSEK31d5lgIKRl7V7SHZJNbe/lcqHTR+1O6K15qW1GTzw/k4mxgbxyV3TiQmyvjintdkjwvDzMttUh845Wc2qtHyunRxr8+jsignRpOdVnK5rtmZtuX9XmE2Ke84fwv5cY2f79tQ3Wvjtsj38a30miybFMM6OrVB7W/MUxrTccvLLa5ndB+WWZpPigqioaSCjsBKArVklaAfWz8H4ZDYq0vqm0ZlFVdQ1WGTKoh1IQreF1ka5JW4GBLTfP+SjbTmsSsvn15/sZsbTKTy78iCFFW23BWu0aH7/2V7+9vUBLh0XxdLbJnfaT7klH08zc0eF8/W+vE7ndDdfmGu+UGeLi8dE4mFS7V4cbV7u39X6eUuXT4gmJqhfu6P0qtoG7liayvs/ZHPv7ESeWTTW5T6OXz4+msB+nigF5w/vu3bRrRcYbT5cjLeHMaXRkUZFBZCWW95mhtPpC6I9bMolJKHbpmA/FB2A0Vd0eFhKej4TYwfw7u1TGD9oAM+vPsSMp1P4nw93na4dnqpr5Bdvb+M/W47xi5mDee6a8Xh7dL2uecnYKEqr6zvswV1T38gHP2Tzk1ERRHdhql9If29mDRvI5zutT4/ccKiI2GDfLreubcnTbOKe8xPZmV3a5ncoqKjhmlc2s/5gIX+9Ygy/mjfc5ZI5GF3/Hp47jOsnxxLav+8u9sWH+BLs53U6oW/JLGZSXFC3/p3Z06ioAKrrGtvsGLU/txwvs4khvTyl82zgHj1ce9veZaBMHZZb8str2Hu8nEfmDWd6YijTE0PJLKzkzU1ZfJSawyfbc5g2OISqugb2HC/jzwuT+Pm0+G6HdN6wUPx9PPjvrhPMHm794/xnO49TWl3PTZ1sj2XNwgnRrE4v4PsjJWcsHKpvtLD5cBGXT2i9aVXXXTUpmsUph1i8OuN0+SajoJKb/72V4so6Xrsp2e59w/tad859TymlmBgbxPajJymtriMtr5yHL2yz30yfa56SuO9E+Rnz8dNyK0gM62/XzSjOVnIGO9Ncbok/r8O55muaasEtd6IZPLA/f144mi2/ncOjC0aQVVzFgbwKXr5xUo+SORg9uOclRbByX77Ver3Wmjc3HWV4uH+39o6cOzIcPy9zm1WdO46VUlXX2O36eUvG7jKD2ZpVwveZxWw9UsJVSzYZnyx+MdXlk7kjJccHkVlUxVd789Aahy0oamlYuD+eZtWmjp6WWy71czuRhN6ZvN3GphSdzG5ZnV5A9IB+DLfSKS7Q15O7Zg1h/a9n8/3v5thtLvUlYyOpqG1gvZWGWj9knSQtt9ymqYrW9PMyM390JCv25J7xhrHhUCEmhd069l3bVI747fI93Pj694T4ebHs7hmM7eJ0SHGm5jr6y+sO08/T3OXppb3By8NEYtiZm0YXVdZSWFErM1zsRBJ6Z/YuA2WGEZe2e0hNfSMbDxUxe8TADpOnp9nEAF/7NbefkRhKkK+n1UVGb23KIsDHg8sndH8brismRFNR23DGTJQNXVzu3xkfTzN3zkwgs7CKMdGBfHL39HZb8QrbjYkOxNOsOFpcTXJ8UJ9NmexMUlTAGXPRZYWofTnH37Kz0hr2LYPB54Nf+yPSLZnFnKpv7LWNC9rjaTYxf3Qkq9LyOVX34yg6t+wUX+/L45pzBvVoI4NpQ0II8/c+PSf9x+X+9p2xcfP0BF68fiLv3D6FoF7czeVs4uNpJinKmObpyPnnrY2KDKCospaCihrANTa1cCWS0DtyYruxQUUn5ZaU9AJ8PE19vnEAwKVjI6muazxjFP3OlmNYtOZnU+N79Nxmk9EKYO2BAk5W1bHpcDEWDTPtvEGDl4eJi8dGuswqUFfRXHZxpoTevGK0ueyy/0Q5kYE+8kZuJ5LQO7J3GZg8YcTF7R6itWZ1WgHnJoY6JCFNGRxCaH/v04uMauobeW/rMeaMCLNL6WLh+GjqGzVf7sllw6HuLfcXjvHT5EFcPyXWqRZkjWzVAkB6oNuXJPT2WCyw71MYcgH0a39DgEMFlRwvPeWwGRlmk+KiMRGkpBdQWWvst1lcVWe36XJJUQEMDevPpzuOs/5gEdOGdG+5v+h7wyP8+esVY5zq7yvAx5PYYF/2nyintqGRw4WVckHUjpznb9rZHE+F8pzOZ7ek9f7GBZ25dFwUtQ0WVu3P563NWSSG9edcO/X3Vkpx+YRoUo+eNJb7D+u7FY/CPTW3ADiUX0mDRcsI3Y4kobdn7zIwe8HwBR0elpKeT1JUABGBPn0UWFuTYoOICPDhn6sOsjunjJumxdl1ZeXC8T/OlJnZg+X+QoDxqe9IURWpTT39JaHbjyR0aywW2P8pJM7tcE/Qk1V1bDt60qGjczAaH108NpKs4mr8vT24cqJ9N4GICfJl6uBgEkL9erTcXwj4sWfL8h3H8fE0ES//puxGlv5bc2wzVOR2Wm5Zd7AQi3ZsuaXZJWMjeX3jERYlx+Dnbf+/1sXXTey0g6QQtmieTrkrp4xxgwZgNrlenx5nJQndmn3LwcMHhs3r8LDV6QWE+Hk5xayP8YMGsPi6CczspRq37CQj7CU8wJtgPy9KqupkQZGdScmlNUsj7P8Mhv4EvNu/+t7QaGHdgQJmjwjD5AQjDKUUl46LstsKTiF6i1Lq9Hz0UTLDxa4kobeWtRGqCjott2w7epLymoY+2SdSCHfTPDKXC6L2JSWX1vYtB09fY4TegZT0AjzNinNl1ocQXfaTpAh2HCs9XU8X9iEJvaWaMiOhD5sPXh1feV+dXsCUhBD8faTEIURXTYoL4sO7pjk6DLcjJZeWNjwLNaUw44EODztaXEVGQWWf7hMphBCdkYTerDQbtiyBsddA1PgOD21uhCX1cyGEM5GE3izlL8afFzze+aHpBQwe6Ed8qCyIEEI4D0noALm7YPcHMPUuGBDb4aGVtQ18n1kio3MhhNORhK41fPt7o6PiuQ93evjGQ0XUNVpkv0shhNORhJ6xCo6sg1m/hn4DOj08JT0ffx8PkuPbb6krhBCOcHYndEsjrPwDBCVA8m2dHp5VVEVKeiEzhw3E04l6TAshBJzt89B3vgMF++Hqt8Cj7RZYdQ0WfsgqISW9gDXpBWQWVQFw1cTovo5UCCE6dfYm9LoqSHkKYibDqIWnby6pqmNVWj5r0gvYcKiIytoGvMwmpg4J4efT4rhgRLjsSi+EcEpnb0Lf9AJU5sFPl0LTZhBaay5dvJHjpaeICPDh0nGRzB4exozE0F5pSSuEEPZkU5ZSSs0HngPMwGta66db3X8+8BlwpOmmZVrrP9svTDuryIfvnoORl0LslNM3F1bWcrz0FA/PHcZ9FyTaddcfIYTobZ0mdKWUGXgRmAvkAD8opT7XWu9vdegGrfUlvRCj/a39X2ishQv/dMbN6bkVAJwTHyzJXAjhcmyZqjEZyNBaZ2qt64D3gYWdPMZ5FR6A7Ush+VYIGXLGXel55QCMiJAezUII12NLQo8Gslv8nNN0W2vTlFK7lFJfKaWSrD2RUupOpVSqUiq1sLCwG+HawdqnjU6Ks37T5q70vArCA7wJ8ms740UIIZydLQndWu1Bt/p5OxCntR4HLAY+tfZEWutXtNbJWuvkgQN7Z6u0DjXUwaFvYfRV4Ne2j3l6bgUjIqThvhDCNdmS0HOAQS1+jgFOtDxAa12uta5s+n4F4KmUcr6dH7K3QF0lDJ3b5q76RgsZBZWMkC2xhBAuypaE/gMwVCmVoJTyAq4FPm95gFIqQjVdRVRKTW563mJ7B9tjh1aCyRMSZra560hRFXWNFkbKCF0I4aI6neWitW5QSt0LfIMxbfENrfU+pdRdTfe/DCwC7lZKNQCngGu11q3LMo6XsRpip1rd/Dktt+mCqIzQhRAuyqZ56E1llBWtbnu5xfcvAC/YNzQ7KzsOBftgrvXp8el5FXiaFYND+/dxYEIIYR9nT4epjFXGn4kXWr07PbecIQP74+Vx9pwSIYR7OXuyV8Yq8I+CsFFW707Pq2BkpNTPhRCu6+xI6I31kLkWhl54um9LS6XVdeSW1ciCIiGESzs7Enr2Vqgtb7/ckmcs+R8hI3QhhAs7OxJ6xiowecDg863enZ4rS/6FEK7vLEnoK2HQFPAJtHp3el4FQb6ehPl793FgQghhP+6f0CvyIG8PJM5p95C0PGPJv3RYFEK4MvdP6BmrjT8T2y73B7BYNAfzKmRBkRDC5Z0FCX0l9A+HiDFW7z5WUs2p+kZZ8i+EcHnundAbG+BwijG7pZ1yyuke6DJCF0K4OPdO6Me3QU1Zu9MVAdJyKzApGBomCV0I4drcO6FnrARlgiGz2z0kPa+c+FA/+nmZ+zAwIYSwP7dL6DX1jeSV1Rg/ZKyCmHOgX1C7x6fnVUj9XAjhFtwuof9rXSYXPruOiuITcGJHu7NbAKpqGzhaXC0LioQQbsHtEvqB/HIqaxvYs265ccPQ9uvnB/Jlyb8Qwn24XUI/VlINQP2Bb8FvIESMa/fY9NymhC4jdCGEG3C/hF5cjb+XYkxNKuXRM8HU/q+YnldOf28Pogf068MIhRCid7hVQi+trqO8poFfjakiWFWyprH90TkYI/ThEf6YTLLkXwjh+twqoTeXW2boXVhQLD46iIZGi9Vjtdak5ZVLuUUI4TbcMqFHF22kPHgsGZXebDhUZPXYE2U1VNQ0yAVRIYTbcLuEHkQ5PgU78R+9gBA/Lz7alm312OYe6CNlhC6EcBNuldCzS6q5yDcdhcY8bC4Lx0ezan8BJ6vq2hzbvEvRMEnoQgg34VYJ/WhxNTO9DoB3IERN4OrkGOoaLXy283ibY9PzKogJ6keAj6cDIhVCCPtzq4R+rKSa4WRB5FgwmRkZGcDo6AA+2pbT5tj03HJGyJJ/IYQbcZuEXt9oIb+0kui6TIgYe/r2qycNYt+JcvafKD99W019I5lFVYyUlrlCCDfiNgn9ROkpEjiBp6UWIn+cf75wfBReZtMZF0czCipptGgZoQsh3IrbJPSjxdUkqSzjh8gfR+gDfL2YOyqcz3aeoK7BmJPefEF0uFwQFUK4EbdJ6MdKqkkyZaHNPhAy9Iz7FiXHUFJVR0p6PmDUz709TMSH+DoiVCGE6BVuk9CzS6oZbToK4Ulg9jjjvvMSQwnz9+ajVOPiaHpeBcPC/fEwu82vL4QQ7pPQjxVXkWQ6impRbmnmYTZx5cQY1h4spKCihnRZ8i+EcENuk9Bri47gT9UZF0Rbujo5hkaL5rUNRyiqrJMl/0IIt+MWCV1rTWDpfuMHKyN0gCED+zMxdgBvfpcFyJJ/IYT7cYuEXlpdz+DGTCzKDGFJ7R53dfIg6pq6L8oMFyGEu3GLhH6sxJiyWOU/BDx92j3ukrGR+HiaCPP3JqS/dx9GKIQQvc+j80Oc37GSaiabsrBEzOnwOH8fT+45P5H6dnqkCyGEK3OLhF6Yl024KqUudkKnx94/Z2inxwghhCtyi5KLPrEbAK+YzhO6EEK4K7dI6H4le41vIsY4NhAhhHAgt0joYVUHKPKMAp9AR4cihBAOY1NCV0rNV0odUEplKKUe7eC4c5RSjUqpRfYLsWN1DRYGN2ZSEjCir15SCCGcUqcJXSllBl4EFgCjgOuUUqPaOe7/Ad/YO8iOnMjPJ17lUxc6ui9fVgghnI4tI/TJQIbWOlNrXQe8Dyy0ctx9wCdAgR3j61Tpke0AeMaM78uXFUIIp2NLQo8Gslv8nNN022lKqWjgCuDljp5IKXWnUipVKZVaWFjY1Vitqs/ZCUDQkHPs8nxCCOGqbEnoysptutXP/wR+o7Vu7OiJtNavaK2TtdbJAwcOtDHEjnkX7qVADyA0YpBdnk8IIVyVLQuLcoCW2TIGONHqmGTgfaUUQChwkVKqQWv9qT2C7EhwRTpHPIcQZrL2viOEEGcPWxL6D8BQpVQCcBy4Fri+5QFa64Tm75VSbwJf9EUyp76GyLosdgZO7fWXEkIIZ9dpQtdaNyil7sWYvWIG3tBa71NK3dV0f4d1896kC/ZjxkJ1cJtJN0IIcdaxqZeL1noFsKLVbVYTudb65p6HZZvqozvwg3Y3tRBCiLOJSzfnOnVsO43al6DoYY4ORQghHM6ll/6b8nezX8cRF+rn6FCEEMLhXDehWxrxLzvAPks8g4J8HR2NEEI4nOsm9KJDeFpqOeadSD8vs6OjEUIIh3PdhJ5n9EAvDxzp4ECEEMI5uG5Cz91FLZ6Yw4Y7OhIhhHAKLpvQLbm7SbcMIjokwNGhCCGEU3DNhK41OncX+yzxxAbLBVEhhABXTeilxzDXlrFPxxMbIgldCCHAVRN60wVRGaELIcSPXDOh5+7Ggokj5jjC/L0dHY0QQjgF11z6n7ebXM9YwgKCaGrZK4QQZz2XHaGnI+UWIYRoyfUSemUhVJxgW+0gBklCF0KI01wvoeftAmBHQ6yM0IUQogXXS+jeAZyMv5h9ljjiZMqiEEKc5noJfdBk1o9/hnL6ywhdCCFacL2EDhwrrgYgRtrmCiHEaa6Z0EuqCfP3lra5QgjRgksm9KMl1VI/F0KIVlwyoWeXVMuURSGEaMXlEnpNfSN55TVyQVQIIVpxuYR+vPQUWiMJXQghWnG5hH6sxJjhIgldCCHO5HIJ3d/bg3lJ4cSH+jk6FCGEcCou120xOT6Y5PhgR4chhBBOx+VG6EIIIayThC6EEG5CEroQQrgJSehCCOEmJKELIYSbkIQuhBBuQhK6EEK4CUnoQgjhJpTW2jEvrFQhcLSDQ0KBoj4Kp6sktu6R2LpHYused40tTms90NodDkvonVFKpWqtkx0dhzUSW/dIbN0jsXXP2RiblFyEEMJNSEIXQgg34cwJ/RVHB9ABia17JLbukdi656yLzWlr6EIIIbrGmUfoQgghukASuhBCuAmnS+hKqflKqQNKqQyl1KOOjqclpVSWUmqPUmqnUirVwbG8oZQqUErtbXFbsFJqpVLqUNOfQU4U2xNKqeNN526nUuoiB8U2SCm1RimVppTap5R6oOl2h5+7DmJz+LlTSvkopbYqpXY1xfanptud4by1F5vDz1uLGM1KqR1KqS+afu6V8+ZUNXSllBk4CMwFcoAfgOu01vsdGlgTpVQWkKy1dvhiBaXUTKASWKq1Ht1029+AEq31001vhkFa6984SWxPAJVa67/3dTytYosEIrXW25VS/sA24HLgZhx87jqI7ac4+NwppRTgp7WuVEp5AhuBB4Arcfx5ay+2+TjBvzkApdTDQDIQoLW+pLf+rzrbCH0ykKG1ztRa1wHvAwsdHJNT0lqvB0pa3bwQeKvp+7cwkkGfayc2p6C1ztVab2/6vgJIA6JxgnPXQWwOpw2VTT96Nn1pnOO8tRebU1BKxQAXA6+1uLlXzpuzJfRoILvFzzk4yT/oJhr4Vim1TSl1p6ODsSJca50LRnIAwhwcT2v3KqV2N5VkHFIOakkpFQ9MAL7Hyc5dq9jACc5dU9lgJ1AArNRaO815ayc2cILzBvwT+DVgaXFbr5w3Z0voysptTvNOC8zQWk8EFgC/bCotCNssAYYA44Fc4P8cGYxSqj/wCfCg1rrckbG0ZiU2pzh3WutGrfV4IAaYrJQa7Yg4rGknNoefN6XUJUCB1npbX7yesyX0HGBQi59jgBMOiqUNrfWJpj8LgOUYJSJnkt9Uh22uxxY4OJ7TtNb5Tf/pLMCrOPDcNdVZPwHe0Vova7rZKc6dtdic6dw1xVMKrMWoUTvFeWvWMjYnOW8zgMuarr+9D1yglPoPvXTenC2h/wAMVUolKKW8gGuBzx0cEwBKKb+mC1UopfyAnwB7O35Un/scuKnp+5uAzxwYyxma//E2uQIHnbumC2ivA2la62db3OXwc9debM5w7pRSA5VSA5q+7wdcCKTjHOfNamzOcN601r/VWsdoreMx8lmK1vpGeuu8aa2d6gu4CGOmy2HgMUfH0yKuwcCupq99jo4NeA/jY2Q9xieb24AQYDVwqOnPYCeK7W1gD7C76R9zpINiOxejjLcb2Nn0dZEznLsOYnP4uQPGAjuaYtgL/KHpdmc4b+3F5vDz1irO84EvevO8OdW0RSGEEN3nbCUXIYQQ3SQJXQgh3IQkdCGEcBOS0IUQwk1IQhdCCDchCV0IIdyEJHQhhHAT/x9lBxCzkLni7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Plot accuracy and also run on test set'''\n",
    "resnet_8_r.train_test_predict(x_train,y_train,x_test[:],y_test[:])\n",
    "plot_accs(training_object_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image Processing\n",
    "\n",
    "There are typically four ways to increase the size of our dataset through image augmentation:\n",
    "\n",
    "1) Rotating the image\n",
    "\n",
    "2) Distorting the colors by changing the RGB values very slightly \n",
    "\n",
    "3) Cropping the image\n",
    "\n",
    "4) Mirroring the image \n",
    "\n",
    "I will initially focus on cropping and mirroring, which intuitively are likely to lead to limit the number of poor quality new images that we generate. I will then try distortions, and then rotations.\n",
    "\n",
    "The general approach will be to create a mirror image for each image (2 images total), and then 5 crops for each image (10 images). Once we add 5 distortions per image (50 images total), and 4 minor rotations (200 images per initial image), our dataset will have grown 200x, from 20000 imagess to 4,000,000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following four functions allow us to mirror, crop, resize and label our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_five_images(image,crop=0.85):\n",
    "    \n",
    "    #create a mirror\n",
    "    image_mirror= ImageOps.mirror(image)\n",
    "    \n",
    "    '''helper function to crop both the image and mirror image'''\n",
    "    def get_crops(x,crop=crop):\n",
    "        #create coordinates for height, cropped height and the height removed (+width)\n",
    "        orig_w = x.size[0]\n",
    "        orig_h = x.size[1]\n",
    "        crop_w = int(crop*orig_w)\n",
    "        crop_h = int(crop*orig_h)\n",
    "        w_rem = orig_w - crop_w\n",
    "        h_rem = orig_h - crop_h\n",
    "\n",
    "        #create 5 crops\n",
    "        x_tl_crp = x.crop((0,0,crop_w,crop_h))\n",
    "        x_tr_crp = x.crop((w_rem,0,orig_w,crop_h))\n",
    "        x_bl_crp = x.crop((0,h_rem,crop_h,orig_h))\n",
    "        x_br_crp = x.crop((w_rem, h_rem, orig_w, orig_h))\n",
    "        x_mid_crp = x.crop((int(w_rem/2),int(h_rem/2),int(orig_w-w_rem/2),int(orig_h-h_rem/2)))\n",
    "        return x_tl_crp, x_tr_crp, x_bl_crp, x_br_crp, x_mid_crp\n",
    "\n",
    "    #call this function for both image and mirror image\n",
    "    tupee = tuple(get_crops(image) + tuple(get_crops(image_mirror)))\n",
    "    return tupee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_images(file,size):\n",
    "    #load image\n",
    "    pil_im = Image.open(file)\n",
    "\n",
    "    #call function to create ten images\n",
    "    tuple_of_ims = create_five_images(pil_im)\n",
    "    #create blank list to store them \n",
    "    list_of_same_im = []\n",
    "    \n",
    "    '''loop through tuple of ten images in order to resize them'''\n",
    "    for im in tuple_of_ims:\n",
    "        #create height, width, and the coefficient to downscale it.\n",
    "        width = im.size[0]\n",
    "        height = im.size[1]\n",
    "        re_size_val = max(width,height)/size\n",
    "\n",
    "        im_vec = np.array(im.resize((int(width//re_size_val),int(height//re_size_val))))\n",
    "        #Pad it out to a full 128 by 128\n",
    "        hor_pad_1 = int((size-im_vec.shape[0])/2)\n",
    "        hor_pad_2 = int((size-im_vec.shape[0]+1)/2)\n",
    "        ver_pad_1 = int((size - im_vec.shape[1])/2)\n",
    "        ver_pad_2 = int((size - im_vec.shape[1]+1)/2)\n",
    "        im_vec = np.pad(im_vec,pad_width=((hor_pad_1,hor_pad_2),(ver_pad_1,ver_pad_2),(0,0)))\n",
    "        list_of_same_im.append(im_vec)\n",
    "        \n",
    "    return list_of_same_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_values(cur_folder,new_folder,sub_folders=3,size=128,start=0,end=2000):\n",
    "\n",
    "    list_of_food = []\n",
    "    unique_foods = {}\n",
    "    x = np.zeros((size,size,3)).astype(np.uint8)\n",
    "    counter_cats, counter =0,0\n",
    "    for food_cat in os.listdir(cur_folder)[0:sub_folders]:\n",
    "        if not os.path.isdir(f'{new_folder}/{food_cat}'):\n",
    "            os.mkdir(f'{new_folder}/{food_cat}')\n",
    "        if (food_cat == '.DS_Store') or (food_cat == 'waffles'):\n",
    "            continue\n",
    "        unique_foods[counter_cats]=food_cat\n",
    "\n",
    "        for file in os.listdir(f'{cur_folder}/{food_cat}')[start:end]:\n",
    "            file_ = f'{cur_folder}/{food_cat}/{file}'\n",
    "\n",
    "            #here we are resizing and adding to the array\n",
    "#             try:\n",
    "            list_of_ten_images_in_vec = create_multiple_images(file_,size=size)\n",
    "            for i in list_of_ten_images_in_vec:\n",
    "                file_to_save = i.astype(np.uint8)\n",
    "                image_to_save = Image.fromarray(file_to_save)\n",
    "\n",
    "                with open(f'{new_folder}/{food_cat}/img{counter}.jpg','wb+') as f:\n",
    "                    image_to_save.save(f)\n",
    "                counter+=1\n",
    "                list_of_food.append(food_cat)\n",
    "#             except:\n",
    "#                 print(f'{food_cat} had an error')\n",
    "#                 print(counter)\n",
    "                \n",
    "        counter_cats+=1\n",
    "    return list_of_food, unique_foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now load the images in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_folder = '/Users/jacoblourie/Downloads/Food_Images/Images'\n",
    "train_folder = '/Users/jacoblourie/computer_vision/food_images_aug/train'\n",
    "test_folder = '/Users/jacoblourie/computer_vision/food_images_aug/test'\n",
    "list_of_food_mircrop, unique_foods_mircrop = create_x_values(cur_folder,train_folder,end=800)\n",
    "list_of_food_mircrop, unique_foods_mircrop = create_x_values(cur_folder,test_folder,start=800)\n",
    "# y_mir_crop = get_y_values(list_of_food_mircrop, unique_foods_mircrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing them with Tensorflow datasets preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 files belonging to 3 classes.\n",
      "Found 6000 files belonging to 3 classes.\n",
      "Using 4200 files for training.\n",
      "Found 6000 files belonging to 3 classes.\n",
      "Using 1800 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_folder,\n",
    "#   validation_split=0,\n",
    "#   subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(128, 128),\n",
    "  batch_size=32)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_folder,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",  \n",
    "  seed=123,\n",
    "  image_size=(128, 128),\n",
    "  batch_size=32)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_folder,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",  \n",
    "  seed=123,\n",
    "  image_size=(128, 128),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheese_plate', 'club_sandwich', 'foie_gras']\n",
      "['cheese_plate', 'club_sandwich', 'foie_gras']\n",
      "['cheese_plate', 'club_sandwich', 'foie_gras']\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.class_names)\n",
    "print(test_ds.class_names)\n",
    "print(val_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section creates caching and pre-fetching for better performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(x,binary='yes'):\n",
    "\n",
    "    #flip between -30' and 30'\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255, input_shape=(128,128,3))(x)\n",
    "    if binary == 'yes':\n",
    "        x = tf.image.random_saturation(x,0,0.25)\n",
    "        x = tf.image.random_hue(x,0.1)\n",
    "        x = layers.experimental.preprocessing.RandomRotation(0.08333)(x)\n",
    "    else:\n",
    "        x = tf.image.random_saturation(x,0,0.0001)\n",
    "        x = tf.image.random_hue(x,0.00001)\n",
    "        x = layers.experimental.preprocessing.RandomRotation(0.000001)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet_w_pp():\n",
    "    #By creating a subclass, we don't need to repeat the train_val_rpedict\n",
    "    \n",
    "    #Initialise with the input shape(ignoring examples) and output shape\n",
    "    def __init__(self, input_dims,pp='yes', output='softmax', classes='False',conv_k_reg=0.001,conv_b_reg=0.001,dense_k_reg=0.001,dense_b_reg=0.001,name='ResNet_512_512_3'): \n",
    "        \n",
    "        #Set regularisers\n",
    "        self.conv_k_reg = tf.keras.regularizers.L2(conv_k_reg)\n",
    "        self.conv_b_reg = tf.keras.regularizers.L2(conv_b_reg)\n",
    "        self.dense_k_reg = tf.keras.regularizers.L2(dense_k_reg)\n",
    "        self.dense_b_reg = tf.keras.regularizers.L2(dense_b_reg)\n",
    "\n",
    "        self.input_im = Input(shape=(input_dims))\n",
    "        \n",
    "        #start with a layer non resnet\n",
    "\n",
    "        x = pre_processing(self.input_im,binary=pp)\n",
    "        x = Conv2D(64,kernel_size=(7,7),padding='valid',strides=(2,2), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x)\n",
    "        x = Activation(activations.relu)(x)\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)\n",
    "        #2 non pool ones\n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x)\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)    \n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x,filters=(128,128))\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)   \n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x,filters=(256,256))\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(2,2))(x)           \n",
    "        for i in range(3):\n",
    "            x = self._resnet_layer(x,filters=(512,512))\n",
    "        x = MaxPool2D(pool_size=(2,2),padding='valid',strides=(1,1))(x)    \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(200,activation='relu',kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.dense_k_reg,bias_regularizer=self.dense_b_reg)(x)\n",
    "        x = Dense(200,activation='relu',kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.dense_k_reg,bias_regularizer=self.dense_b_reg)(x)\n",
    "        activation = output\n",
    "        if output == 'sigmoid':\n",
    "            classes = 1\n",
    "        x = Dense(classes, activation=activation,kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.dense_k_reg,bias_regularizer=self.dense_b_reg)(x)\n",
    "        self.model = Model(inputs = self.input_im, outputs= x,name=name)\n",
    "\n",
    "\n",
    "\n",
    "    def _resnet_layer(self,x, first_kernel=(3,3),second_kernel=(3,3), filters=(64,64)):\n",
    "        f1,f2=filters\n",
    "        #do one full layer convolution, with activation\n",
    "        x_skip = x\n",
    "        #do another 2 layers for the x that you're passing through the longer loops\n",
    "        x = Conv2D(f1, kernel_size=first_kernel,activation='relu',padding='same',strides=(1,1), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x)\n",
    "        x = Conv2D(f2, kernel_size=second_kernel,activation='relu',padding='same',strides=(1,1), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x)        \n",
    "        #conv the skip\n",
    "        x_ = Conv2D(f2, kernel_size=(1,1),padding='same',strides=(1,1), kernel_initializer='he_normal',bias_initializer='he_normal',kernel_regularizer=self.conv_k_reg,bias_regularizer=self.conv_b_reg)(x_skip)\n",
    "        \n",
    "        #add them back to together\n",
    "        x = Add()([x,x_])\n",
    "        #activation both of them\n",
    "        x = Activation(activations.relu)(x)        \n",
    "        return x\n",
    "    \n",
    "    def train_test_predict(self,x_train,y_train,x_test,y_test):\n",
    "        preds_train  = np.argmax(self.model.predict(x_train),axis=-1)\n",
    "        preds_test = np.argmax(self.model.predict(x_test),axis=-1)\n",
    "        self.current_train_prediction_score = {np.sum(y_train - preds_train == 0)/x_train.shape[0]}\n",
    "        self.current_test_prediction_score = {np.sum(y_test - preds_test == 0)/x_test.shape[0]}\n",
    "        print(f'train prediction percentage is {self.current_train_prediction_score}')\n",
    "        print(f'test prediction percentage is {self.current_test_prediction_score}')\n",
    "\n",
    "'''Other helper function'''\n",
    "#Plotting the accuracy of a second val set, and the historic performance of the validations et.\n",
    "def plot_accs(training_object):\n",
    "    val_acc, train_acc = training_object.history['val_acc'], training_object.history['acc']\n",
    "    x = np.linspace(1,len(val_acc),len(val_acc))\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(x,val_acc,) #= go.Scatter(x=x,y=val_acc,name='val_acc'), \n",
    "    plt.scatter(x=x,y=train_acc) # ,name='train_acc')\n",
    "    plt.legend(('val_acc','train_acc'))\n",
    "    #     fig.add_trace(line_1)\n",
    "#     fig.add_trace(line_2)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res_pp = Resnet_w_pp(input_dims = (128,128,3),classes=3)\n",
    "Res_pp.model.compile(optimizer='adam',metrics='acc',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_512_512_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_13 (Rescaling)        (None, 128, 128, 3)  0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.adjust_saturation_12 ( (None, 128, 128, 3)  0           rescaling_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.adjust_hue_12 (TFOpLam (None, 128, 128, 3)  0           tf.image.adjust_saturation_12[0][\n",
      "__________________________________________________________________________________________________\n",
      "random_rotation_11 (RandomRotat (None, 128, 128, 3)  0           tf.image.adjust_hue_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 61, 61, 64)   9472        random_rotation_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 61, 61, 64)   0           conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling2D) (None, 30, 30, 64)   0           activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 30, 30, 64)   36928       max_pooling2d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 30, 30, 64)   4160        max_pooling2d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_168 (Add)                   (None, 30, 30, 64)   0           conv2d_520[0][0]                 \n",
      "                                                                 conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 30, 30, 64)   0           add_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 30, 30, 64)   36928       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 30, 30, 64)   4160        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_169 (Add)                   (None, 30, 30, 64)   0           conv2d_523[0][0]                 \n",
      "                                                                 conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 30, 30, 64)   0           add_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 30, 30, 64)   36928       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 30, 30, 64)   36928       conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 30, 30, 64)   4160        activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_170 (Add)                   (None, 30, 30, 64)   0           conv2d_526[0][0]                 \n",
      "                                                                 conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 30, 30, 64)   0           add_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling2D) (None, 15, 15, 64)   0           activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 15, 15, 128)  73856       max_pooling2d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 15, 15, 128)  8320        max_pooling2d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_171 (Add)                   (None, 15, 15, 128)  0           conv2d_529[0][0]                 \n",
      "                                                                 conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 15, 15, 128)  0           add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 15, 15, 128)  147584      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 15, 15, 128)  16512       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_172 (Add)                   (None, 15, 15, 128)  0           conv2d_532[0][0]                 \n",
      "                                                                 conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 15, 15, 128)  0           add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 15, 15, 128)  147584      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 15, 15, 128)  147584      conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 15, 15, 128)  16512       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_173 (Add)                   (None, 15, 15, 128)  0           conv2d_535[0][0]                 \n",
      "                                                                 conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 15, 15, 128)  0           add_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling2D) (None, 7, 7, 128)    0           activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 7, 7, 256)    295168      max_pooling2d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 7, 7, 256)    33024       max_pooling2d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_174 (Add)                   (None, 7, 7, 256)    0           conv2d_538[0][0]                 \n",
      "                                                                 conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 7, 7, 256)    0           add_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 7, 7, 256)    590080      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 7, 7, 256)    65792       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_175 (Add)                   (None, 7, 7, 256)    0           conv2d_541[0][0]                 \n",
      "                                                                 conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 7, 7, 256)    0           add_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 7, 7, 256)    590080      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 7, 7, 256)    590080      conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 7, 7, 256)    65792       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_176 (Add)                   (None, 7, 7, 256)    0           conv2d_544[0][0]                 \n",
      "                                                                 conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 7, 7, 256)    0           add_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling2D) (None, 3, 3, 256)    0           activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 3, 3, 512)    1180160     max_pooling2d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 3, 3, 512)    131584      max_pooling2d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_177 (Add)                   (None, 3, 3, 512)    0           conv2d_547[0][0]                 \n",
      "                                                                 conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 3, 3, 512)    0           add_177[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 3, 3, 512)    2359808     activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 3, 3, 512)    262656      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_178 (Add)                   (None, 3, 3, 512)    0           conv2d_550[0][0]                 \n",
      "                                                                 conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 3, 3, 512)    0           add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 3, 3, 512)    2359808     activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 3, 3, 512)    2359808     conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 3, 3, 512)    262656      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_179 (Add)                   (None, 3, 3, 512)    0           conv2d_553[0][0]                 \n",
      "                                                                 conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 3, 3, 512)    0           add_179[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling2D) (None, 2, 2, 512)    0           activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 2048)         0           max_pooling2d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 200)          409800      flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 200)          40200       dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 3)            603         dense_43[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 18,593,515\n",
      "Trainable params: 18,593,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Res_pp.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_pp = \"pp_mod/weights{epoch:04d}\"\n",
    "checkpoint_dir_pp = os.path.dirname(checkpoint_path_pp)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback_ = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path_pp,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "750/750 [==============================] - 1355s 2s/step - loss: 42.6029 - acc: 0.4054 - val_loss: 12.9002 - val_acc: 0.5679\n",
      "\n",
      "Epoch 00001: saving model to pp_mod/weights0001\n",
      "Epoch 2/25\n",
      "750/750 [==============================] - 1359s 2s/step - loss: 12.3632 - acc: 0.5233 - val_loss: 10.7901 - val_acc: 0.6245\n",
      "\n",
      "Epoch 00002: saving model to pp_mod/weights0002\n",
      "Epoch 3/25\n",
      "750/750 [==============================] - 1279s 2s/step - loss: 10.4408 - acc: 0.5774 - val_loss: 9.2066 - val_acc: 0.6410\n",
      "\n",
      "Epoch 00003: saving model to pp_mod/weights0003\n",
      "Epoch 4/25\n",
      "750/750 [==============================] - 960s 1s/step - loss: 8.9037 - acc: 0.6154 - val_loss: 7.8715 - val_acc: 0.6421\n",
      "\n",
      "Epoch 00004: saving model to pp_mod/weights0004\n",
      "Epoch 5/25\n",
      "750/750 [==============================] - 1015s 1s/step - loss: 7.5753 - acc: 0.6468 - val_loss: 6.6777 - val_acc: 0.6676\n",
      "\n",
      "Epoch 00005: saving model to pp_mod/weights0005\n",
      "Epoch 6/25\n",
      "750/750 [==============================] - 1024s 1s/step - loss: 6.4293 - acc: 0.6503 - val_loss: 5.6253 - val_acc: 0.6498\n",
      "\n",
      "Epoch 00006: saving model to pp_mod/weights0006\n",
      "Epoch 7/25\n",
      "750/750 [==============================] - 1011s 1s/step - loss: 5.3977 - acc: 0.6521 - val_loss: 4.6780 - val_acc: 0.6767\n",
      "\n",
      "Epoch 00007: saving model to pp_mod/weights0007\n",
      "Epoch 8/25\n",
      "750/750 [==============================] - 1021s 1s/step - loss: 4.4869 - acc: 0.6604 - val_loss: 3.8582 - val_acc: 0.6740\n",
      "\n",
      "Epoch 00008: saving model to pp_mod/weights0008\n",
      "Epoch 9/25\n",
      "750/750 [==============================] - 1015s 1s/step - loss: 3.6808 - acc: 0.6703 - val_loss: 3.1357 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00009: saving model to pp_mod/weights0009\n",
      "Epoch 10/25\n",
      "750/750 [==============================] - 1001s 1s/step - loss: 2.9940 - acc: 0.6789 - val_loss: 2.5270 - val_acc: 0.7098\n",
      "\n",
      "Epoch 00010: saving model to pp_mod/weights0010\n",
      "Epoch 11/25\n",
      "750/750 [==============================] - 1000s 1s/step - loss: 2.4388 - acc: 0.6865 - val_loss: 2.1184 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00011: saving model to pp_mod/weights0011\n",
      "Epoch 12/25\n",
      "750/750 [==============================] - 1008s 1s/step - loss: 1.9992 - acc: 0.6914 - val_loss: 1.9251 - val_acc: 0.6093\n",
      "\n",
      "Epoch 00012: saving model to pp_mod/weights0012\n",
      "Epoch 13/25\n",
      "750/750 [==============================] - 996s 1s/step - loss: 1.6803 - acc: 0.6847 - val_loss: 1.4586 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00013: saving model to pp_mod/weights0013\n",
      "Epoch 14/25\n",
      "750/750 [==============================] - 1002s 1s/step - loss: 1.4247 - acc: 0.6901 - val_loss: 1.2386 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00014: saving model to pp_mod/weights0014\n",
      "Epoch 15/25\n",
      "750/750 [==============================] - 999s 1s/step - loss: 1.2402 - acc: 0.6948 - val_loss: 1.1213 - val_acc: 0.7014\n",
      "\n",
      "Epoch 00015: saving model to pp_mod/weights0015\n",
      "Epoch 16/25\n",
      "750/750 [==============================] - 1010s 1s/step - loss: 1.1059 - acc: 0.6999 - val_loss: 1.0034 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00016: saving model to pp_mod/weights0016\n",
      "Epoch 17/25\n",
      "750/750 [==============================] - 993s 1s/step - loss: 1.0181 - acc: 0.7043 - val_loss: 0.9743 - val_acc: 0.7095\n",
      "\n",
      "Epoch 00017: saving model to pp_mod/weights0017\n",
      "Epoch 18/25\n",
      "750/750 [==============================] - 994s 1s/step - loss: 0.9462 - acc: 0.7094 - val_loss: 0.9190 - val_acc: 0.7088\n",
      "\n",
      "Epoch 00018: saving model to pp_mod/weights0018\n",
      "Epoch 19/25\n",
      "750/750 [==============================] - 1008s 1s/step - loss: 0.9086 - acc: 0.7155 - val_loss: 0.8801 - val_acc: 0.7126\n",
      "\n",
      "Epoch 00019: saving model to pp_mod/weights0019\n",
      "Epoch 20/25\n",
      "750/750 [==============================] - 996s 1s/step - loss: 0.8912 - acc: 0.7119 - val_loss: 0.8705 - val_acc: 0.7202\n",
      "\n",
      "Epoch 00020: saving model to pp_mod/weights0020\n",
      "Epoch 21/25\n",
      "750/750 [==============================] - 1002s 1s/step - loss: 0.8515 - acc: 0.7256 - val_loss: 0.9619 - val_acc: 0.6681\n",
      "\n",
      "Epoch 00021: saving model to pp_mod/weights0021\n",
      "Epoch 22/25\n",
      "750/750 [==============================] - 1009s 1s/step - loss: 0.8450 - acc: 0.7268 - val_loss: 0.8883 - val_acc: 0.6969\n",
      "\n",
      "Epoch 00022: saving model to pp_mod/weights0022\n",
      "Epoch 23/25\n",
      "750/750 [==============================] - 1025s 1s/step - loss: 0.8252 - acc: 0.7333 - val_loss: 0.8318 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00023: saving model to pp_mod/weights0023\n",
      "Epoch 24/25\n",
      "750/750 [==============================] - 1015s 1s/step - loss: 0.8107 - acc: 0.7407 - val_loss: 0.8484 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00024: saving model to pp_mod/weights0024\n",
      "Epoch 25/25\n",
      "750/750 [==============================] - 1007s 1s/step - loss: 0.8067 - acc: 0.7320 - val_loss: 0.8781 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00025: saving model to pp_mod/weights0025\n"
     ]
    }
   ],
   "source": [
    "training_object_pp = Res_pp.model.fit(train_ds,validation_data = val_ds,epochs=25, batch_size = 30,validation_batch_size=150,callbacks=[cp_callback_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "750/750 [==============================] - 1192s 2s/step - loss: 0.8033 - acc: 0.7389 - val_loss: 0.8961 - val_acc: 0.7052\n",
      "\n",
      "Epoch 00001: saving model to pp_mod/weights0001\n",
      "Epoch 2/25\n",
      "750/750 [==============================] - 1075s 1s/step - loss: 0.7999 - acc: 0.7372 - val_loss: 0.8194 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00002: saving model to pp_mod/weights0002\n",
      "Epoch 3/25\n",
      "750/750 [==============================] - 1092s 1s/step - loss: 0.7963 - acc: 0.7383 - val_loss: 0.8089 - val_acc: 0.7431\n",
      "\n",
      "Epoch 00003: saving model to pp_mod/weights0003\n",
      "Epoch 4/25\n",
      "750/750 [==============================] - 1110s 1s/step - loss: 0.7871 - acc: 0.7452 - val_loss: 0.8143 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00004: saving model to pp_mod/weights0004\n",
      "Epoch 5/25\n",
      "750/750 [==============================] - 1094s 1s/step - loss: 0.7876 - acc: 0.7434 - val_loss: 0.8060 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00005: saving model to pp_mod/weights0005\n",
      "Epoch 6/25\n",
      "750/750 [==============================] - 1046s 1s/step - loss: 0.7743 - acc: 0.7482 - val_loss: 0.7829 - val_acc: 0.7581\n",
      "\n",
      "Epoch 00006: saving model to pp_mod/weights0006\n",
      "Epoch 7/25\n",
      "750/750 [==============================] - 1031s 1s/step - loss: 0.7750 - acc: 0.7477 - val_loss: 0.8825 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00007: saving model to pp_mod/weights0007\n",
      "Epoch 8/25\n",
      "750/750 [==============================] - 1044s 1s/step - loss: 0.7699 - acc: 0.7548 - val_loss: 0.8227 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00008: saving model to pp_mod/weights0008\n",
      "Epoch 9/25\n",
      "750/750 [==============================] - 1015s 1s/step - loss: 0.7628 - acc: 0.7551 - val_loss: 0.8342 - val_acc: 0.7398\n",
      "\n",
      "Epoch 00009: saving model to pp_mod/weights0009\n",
      "Epoch 10/25\n",
      "750/750 [==============================] - 1053s 1s/step - loss: 0.7562 - acc: 0.7573 - val_loss: 0.7932 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00010: saving model to pp_mod/weights0010\n",
      "Epoch 11/25\n",
      "750/750 [==============================] - 1029s 1s/step - loss: 0.7512 - acc: 0.7604 - val_loss: 0.7735 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00011: saving model to pp_mod/weights0011\n",
      "Epoch 12/25\n",
      "750/750 [==============================] - 1081s 1s/step - loss: 0.7456 - acc: 0.7613 - val_loss: 0.7780 - val_acc: 0.7524\n",
      "\n",
      "Epoch 00012: saving model to pp_mod/weights0012\n",
      "Epoch 13/25\n",
      "750/750 [==============================] - 1114s 1s/step - loss: 0.7463 - acc: 0.7640 - val_loss: 0.8350 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00013: saving model to pp_mod/weights0013\n",
      "Epoch 14/25\n",
      "750/750 [==============================] - 1050s 1s/step - loss: 0.7396 - acc: 0.7655 - val_loss: 0.8289 - val_acc: 0.7371\n",
      "\n",
      "Epoch 00014: saving model to pp_mod/weights0014\n",
      "Epoch 15/25\n",
      "750/750 [==============================] - 1046s 1s/step - loss: 0.7338 - acc: 0.7692 - val_loss: 0.8075 - val_acc: 0.7476\n",
      "\n",
      "Epoch 00015: saving model to pp_mod/weights0015\n",
      "Epoch 16/25\n",
      "750/750 [==============================] - 1094s 1s/step - loss: 0.7364 - acc: 0.7691 - val_loss: 0.8465 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00016: saving model to pp_mod/weights0016\n",
      "Epoch 17/25\n",
      "750/750 [==============================] - 1088s 1s/step - loss: 0.7349 - acc: 0.7668 - val_loss: 0.7824 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00017: saving model to pp_mod/weights0017\n",
      "Epoch 18/25\n",
      "750/750 [==============================] - 1154s 2s/step - loss: 0.7291 - acc: 0.7721 - val_loss: 0.7877 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00018: saving model to pp_mod/weights0018\n",
      "Epoch 19/25\n",
      "750/750 [==============================] - 1203s 2s/step - loss: 0.7228 - acc: 0.7736 - val_loss: 0.7803 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00019: saving model to pp_mod/weights0019\n",
      "Epoch 20/25\n",
      "750/750 [==============================] - 1366s 2s/step - loss: 0.7297 - acc: 0.7710 - val_loss: 0.7918 - val_acc: 0.7436\n",
      "\n",
      "Epoch 00020: saving model to pp_mod/weights0020\n",
      "Epoch 21/25\n",
      "750/750 [==============================] - 1446s 2s/step - loss: 0.7156 - acc: 0.7776 - val_loss: 0.8078 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00021: saving model to pp_mod/weights0021\n",
      "Epoch 22/25\n",
      "750/750 [==============================] - 1379s 2s/step - loss: 0.7215 - acc: 0.7783 - val_loss: 0.7917 - val_acc: 0.7448\n",
      "\n",
      "Epoch 00022: saving model to pp_mod/weights0022\n",
      "Epoch 23/25\n",
      "750/750 [==============================] - 1451s 2s/step - loss: 0.7099 - acc: 0.7785 - val_loss: 0.9457 - val_acc: 0.6810\n",
      "\n",
      "Epoch 00023: saving model to pp_mod/weights0023\n",
      "Epoch 24/25\n",
      "750/750 [==============================] - 1403s 2s/step - loss: 0.7141 - acc: 0.7800 - val_loss: 0.7851 - val_acc: 0.7483\n",
      "\n",
      "Epoch 00024: saving model to pp_mod/weights0024\n",
      "Epoch 25/25\n",
      "750/750 [==============================] - 1157s 2s/step - loss: 0.7172 - acc: 0.7791 - val_loss: 0.8095 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00025: saving model to pp_mod/weights0025\n"
     ]
    }
   ],
   "source": [
    "training_object_pp2 = Res_pp.model.fit(train_ds,validation_data = val_ds,epochs=25, batch_size = 30,validation_batch_size=150,callbacks=[cp_callback_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Val performance from first 25 epochs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-149-4ae7649b19aa>:78: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training and Val performance from first 25 epochs:')\n",
    "plot_accs(training_object_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run on train set\n",
    "\n",
    "We need to load another instance of the model without the preprocessing steps (Tf doesn't automatically handle this for tf.image... library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res_pptest = Resnet_w_pp(input_dims = (128,128,3),classes=3,pp='no')\n",
    "Res_pptest.model.compile(optimizer='adam',metrics='acc',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdece79e2e0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res_pptest.model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 16s 257ms/step - loss: 0.8562 - acc: 0.7140\n"
     ]
    }
   ],
   "source": [
    "preds = Res_pptest.model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 71.4% on test set, versus 57% without image augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
